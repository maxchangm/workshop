---
theme: nord
colorSchema: dark
title: RAG Workshop - Day 3
class: text-center
transition: slide-left
mdc: true
---

# RAG Workshop - Day 3

<div class="text-6xl mb-8">ğŸ§  + ğŸ›¡ï¸ = â­</div>

<div class="text-2xl opacity-75">Advanced RAG: Query Intelligence & Self-Correction</div>

<div class="abs-br m-6 text-sm opacity-50">
  HKPF Workshop
</div>

<!--
**Welcome to Day 3 (2 mins)**

- Day 1: We built the Engine (Keyword, BM25, Vector retrievers)
- Day 2: We built the Fuel Injection (Hybrid Search, Reranking, Docling)
- Day 3: Today, we build the **Driver** â€” systems that fix bad queries, route to the right tools, and correct their own mistakes
- The Shift: Days 1 & 2 assumed the query is perfect. Reality: users write bad queries. Documents are complex.

å»£æ±è©±ï¼š
- Day 1ï¼šæˆ‘å“‹æ•´å’—å€‹ Engine (Keyword, BM25, Vector retrievers)
- Day 2ï¼šæˆ‘å“‹åŠ å’—ç‡ƒæ²¹å™´å°„ (Hybrid Search, Reranking, Docling)
- Day 3ï¼šä»Šæ—¥ï¼Œæˆ‘å“‹è¦æ•´ **å¸æ©Ÿ (Driver)** â€” ä¸€å€‹è­˜å¾—ä¿®æ­£çˆ› Queryã€è­˜æ€å·¥å…·ã€è­˜å¾—è‡ªæˆ‘ä¿®æ­£éŒ¯èª¤å˜…ç³»çµ±
- è½‰è®Šï¼šDay 1 åŒ Day 2 å‡è¨­å€‹ query ä¿‚å®Œç¾å˜…ã€‚ç¾å¯¦ä¿‚ï¼šç”¨æˆ¶æœƒå¯«çˆ› queryï¼Œæ–‡ä»¶äº¦éƒ½å¥½è¤‡é›œã€‚
-->

---
layout: center
---

# The 3-Day Journey

<div class="grid grid-cols-3 gap-8 text-center mt-8">
  <v-click>
  <div class="p-6 border-2 border-blue-500 rounded-xl opacity-50">
    <div class="text-4xl mb-3">ğŸ”</div>
    <div class="font-bold text-xl">Day 1: Retrieval</div>
    <div class="text-sm mt-2">Keyword â†’ BM25 â†’ Vector</div>
    <div class="text-xs mt-2 text-green-400">âœ… Complete</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-6 border-2 border-green-500 rounded-xl opacity-50">
    <div class="text-4xl mb-3">ğŸ”—</div>
    <div class="font-bold text-xl">Day 2: Precision</div>
    <div class="text-sm mt-2">RRF + Reranking + Docling</div>
    <div class="text-xs mt-2 text-green-400">âœ… Complete</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-6 border-2 border-purple-500 rounded-xl bg-purple-900/20">
    <div class="text-4xl mb-3">ğŸ§ </div>
    <div class="font-bold text-xl text-purple-400">Day 3: Intelligence</div>
    <div class="text-sm mt-2">Query Intel + Self-Correction</div>
    <div class="text-xs mt-2 text-yellow-400">â¬…ï¸ You Are Here</div>
  </div>
  </v-click>
</div>

<!--
**The 3-Day Journey (2 mins)**

- Day 1: Three retrieval methods â€” Keyword (exact match), BM25 (statistical), Vector (semantic). Measured with DeepEval.
- Day 2: Combined them â€” Hybrid Search (RRF fusion), Reranking (BGE model), Docling (PDF parsing with tables, images, metadata)
- Day 3: Today we add intelligence â€” the system fixes bad queries, routes to the right strategy, and corrects its own mistakes
- Key insight: You already built the engine. Today you learn to drive.

å»£æ±è©±ï¼š
- Day 1ï¼šä¸‰ç¨® retrieval æ–¹æ³• â€” Keyword (ç²¾æº–åŒ¹é…)ã€BM25 (çµ±è¨ˆ)ã€Vector (èªç¾©)ã€‚ç”¨ DeepEval åšŸåº¦é‡ã€‚
- Day 2ï¼šå°‡ä½¢å“‹çµåˆ â€” Hybrid Search (RRF èåˆ)ã€Reranking (BGE æ¨¡å‹é‡æ’)ã€Docling (PDF è§£æï¼ŒåŒ…åŸ‹è¡¨æ ¼ã€åœ–ç‰‡ã€metadata)
- Day 3ï¼šä»Šæ—¥åŠ æ™ºèƒ½ â€” ç³»çµ±è­˜å¾—ä¿®æ­£çˆ› queryï¼Œè·¯ç”±å»å•±å˜…ç­–ç•¥ï¼ŒåŒåŸ‹ä¿®æ­£è‡ªå·±å˜…éŒ¯èª¤
- é—œéµï¼šä½ å·²ç¶“æ•´å¥½å‰¯å¼•æ“ã€‚ä»Šæ—¥ä¿‚å­¸æ¸è»Šã€‚
-->

---
layout: center
---

# What You've Built: The Complete Pipeline

<Transform :scale="1.4" origin="center">

```mermaid
flowchart LR
    PDF[ğŸ“„ PDF] --> DOC[ğŸ”§ Docling]
    DOC --> CHUNK[âœ‚ï¸ Chunker]
    CHUNK --> DB[(ğŸ—„ï¸ DuckDB)]
    DB --> BM25[ğŸ“ BM25]
    DB --> VEC[ğŸ§  Vector]
    BM25 --> RRF[ğŸ”— RRF]
    VEC --> RRF
    RRF --> RR[âš–ï¸ Reranker]
    RR --> LLM[ğŸ¤– LLM]
    LLM --> ANS[ğŸ’¡ Answer]

    style PDF fill:#3b82f6,color:#fff
    style DOC fill:#3b82f6,color:#fff
    style CHUNK fill:#3b82f6,color:#fff
    style DB fill:#22c55e,color:#000
    style BM25 fill:#22c55e,color:#000
    style VEC fill:#22c55e,color:#000
    style RRF fill:#eab308,color:#000
    style RR fill:#eab308,color:#000
    style LLM fill:#a855f7,color:#fff
    style ANS fill:#6b7280,color:#fff
```

</Transform>

<v-click>
<div class="mt-10 text-center text-lg text-green-400">
  Document Ingestion â†’ Hybrid Search â†’ Reranking â†’ Generation
</div>
</v-click>

<!--
**What You've Built (3 mins)**

- Walk through the pipeline left to right:
  - Docling: PDF parsing with table extraction, image descriptions, metadata
  - Chunker: Token-aware chunking with section titles
  - DuckDB: Embedded database with HNSW + FTS indexes
  - BM25 + Vector: Two search methods running in parallel
  - RRF: Democratic fusion â€” rewards docs that both methods agree on
  - Reranker: Neural re-scoring for precision
  - LLM: Generate grounded answer from context
- This is a production-grade pipeline. But it has one assumption...

å»£æ±è©±ï¼š
- ç”±å·¦è‡³å³è¡Œä¸€æ¬¡å€‹ pipelineï¼š
  - Doclingï¼šPDF è§£æï¼ŒåšåŸ‹è¡¨æ ¼æå–ã€åœ–ç‰‡æè¿°ã€metadata
  - Chunkerï¼šè­˜åˆ† Token åŒ Section title å˜…åˆ‡åˆ†
  - DuckDBï¼šåµŒå…¥å¼æ•¸æ“šåº«ï¼Œæœ‰ HNSW + FTS indexes
  - BM25 + Vectorï¼šå…©ç¨®æœå°‹æ–¹æ³•å¹³è¡Œè·‘
  - RRFï¼šæ°‘ä¸»å¼èåˆ â€” çå‹µå…©ç¨®æ–¹æ³•éƒ½æµåˆ°å˜…æ–‡ä»¶
  - Rerankerï¼šç¥ç¶“ç¶²çµ¡é‡æ’ï¼Œæå‡æº–ç¢ºåº¦
  - LLMï¼šæ ¹æ“š Context ç”Ÿæˆæœ‰æ ¹æ“šå˜…ç­”æ¡ˆ
- å‘¢å€‹ä¿‚ Production-grade å˜… pipelineã€‚ä½†ä½¢æœ‰ä¸€å€‹å‡è¨­...
-->

---
layout: center
---

# Your Building Blocks

<div class="grid grid-cols-2 gap-6 text-sm">
  <v-click>
  <div class="p-4 border border-green-500 rounded-lg">
    <div class="font-bold text-green-400 mb-2">ğŸ’» From Days 1-2 (Local)</div>
    <div class="font-mono text-xs space-y-1">
      <div>_search_bm25(conn, query, limit)</div>
      <div>_search_vector(conn, query_vec, limit)</div>
      <div>_hybrid_search(conn, query, top_k)</div>
      <div>_generate_answer(query, chunks)</div>
      <div>ollama.embed(model, input)</div>
      <div>DuckDB with HNSW + FTS indexes</div>
    </div>
  </div>
  </v-click>
  <v-click>
  <div class="p-4 border border-purple-500 rounded-lg">
    <div class="font-bold text-purple-400 mb-2">â˜ï¸ New Today (Remote GPU)</div>
    <div class="font-mono text-xs space-y-1">
      <div>chat_client â†’ qwen3-vl-8b</div>
      <div>_rerank() â†’ qwen3-vl-reranker-2b</div>
      <div class="mt-2 text-yellow-400">âš¡ GPU inference: ~1-2s</div>
      <div class="text-yellow-400">vs CPU: 5-15s</div>
    </div>
  </div>
  </v-click>
</div>

<v-click>
<div class="mt-6 text-center text-sm opacity-75">
  You already have 10+ working components. Today you arrange them into smarter systems.
</div>
</v-click>

<!--
**Your Building Blocks (2 mins)**

- Left side: Everything from Days 1-2 â€” search functions, embeddings, database. All LOCAL.
- Right side: Two new remote endpoints on Modal GPU â€” fast chat model (8B params) and reranker
- Key: Local search stays local (data sovereignty). Remote GPU handles heavy reasoning.
- "You already built the engine. Today you learn to drive."

å»£æ±è©±ï¼š
- å·¦é‚Šï¼šDay 1-2 å˜…æ‰€æœ‰å˜¢ â€” search functions, embeddings, databaseã€‚å…¨éƒ¨éƒ½ä¿‚ LOCAL å˜…ã€‚
- å³é‚Šï¼šå…©å€‹æ–°å˜… Remote ç«¯é» (Modal GPU) â€” å¿«é€Ÿ Chat model (8B params) åŒ Reranker
- é—œéµï¼šLocal search ç•™è¿”å–ºæœ¬åœ° (æ•¸æ“šä¸»æ¬Š)ã€‚Remote GPU è² è²¬é‡å‹æ¨ç†ã€‚
- ã€Œä½ å·²ç¶“æ•´å¥½å‰¯å¼•æ“ã€‚ä»Šæ—¥ä¿‚å­¸æ¸è»Šã€‚ã€
-->

---
layout: center
---

# Architecture: Local Search + Remote Brain

<div class="grid grid-cols-2 gap-12">
  <v-click>
  <div class="p-6 border-2 border-green-500 rounded-xl">
    <div class="text-3xl mb-4 text-green-400">ğŸ’» Local (Your Laptop)</div>
    <div class="text-sm mb-2 font-bold">Data Stays Here</div>
    <div class="text-xs opacity-75">â€¢ DuckDB (Vector Store + FTS)</div>
    <div class="text-xs opacity-75">â€¢ Embeddings (qwen3-embedding:0.6b)</div>
    <div class="text-xs opacity-75">â€¢ Hybrid Search Logic</div>
    <div class="text-green-400 mt-3 text-sm">ğŸ”’ Documents never leave</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-6 border-2 border-purple-500 rounded-xl">
    <div class="text-3xl mb-4 text-purple-400">â˜ï¸ Remote (Modal GPU)</div>
    <div class="text-sm mb-2 font-bold">Heavy Lifting</div>
    <div class="text-xs opacity-75">â€¢ qwen3-vl-8b (Generation)</div>
    <div class="text-xs opacity-75">â€¢ qwen3-vl-reranker-2b (Grading)</div>
    <div class="text-xs opacity-75">â€¢ Query Rewriting / Classification</div>
    <div class="text-purple-400 mt-3 text-sm">âš¡ GPU: ~1-2s per call</div>
  </div>
  </v-click>
</div>

<v-click>
<div class="mt-6 text-center text-sm text-yellow-400">
  Real-world pattern: sensitive data stays local, inference offloaded to GPU
</div>
</v-click>

<!--
**Architecture: Local + Remote (3 mins)**

- Government IT reality: You can't send sensitive docs to external APIs
- But you can't run 8B param models fast on standard laptops
- Solution: Hybrid architecture â€” local DB + remote inference
- Local: Documents, embeddings, search indexes stay on your machine
- Remote: We send queries/context to secure GPU endpoint for reasoning
- This mirrors real production setups in government IT

å»£æ±è©±ï¼š
- æ”¿åºœ IT ç¾å¯¦ï¼šä½ å””å¯ä»¥å°‡æ•æ„Ÿæ–‡ä»¶ send å»å‡ºé¢å˜… API
- ä½†ä½ åˆå””å¯ä»¥ç”¨æ™®é€š Laptop è·‘å¾—éƒ 8B param models
- è§£æ±ºæ–¹æ¡ˆï¼šHybrid æ¶æ§‹ â€” Local DB + Remote æ¨ç†
- Localï¼šæ–‡ä»¶ã€Embeddingsã€Search indexes å…¨éƒ¨ç•™å–ºä½ éƒ¨æ©Ÿ
- Remoteï¼šæˆ‘å“‹ send query åŒ context å»å®‰å…¨å˜… GPU endpoint åšæ¨ç†
- å‘¢å€‹å¥½åæ˜ çœŸå¯¦æ”¿åºœ IT å˜… setup
-->

---
layout: center
---

# How to Call the Remote LLM

<div class="grid grid-cols-2 gap-8 text-sm">
  <v-click>
  <div class="p-4 border border-red-500 rounded-lg bg-red-900/10">
    <div class="font-bold text-red-400 mb-2">âŒ Before (Part 3 â€” Local CPU)</div>

```python
resp = ollama.chat(
    model="granite4:350m",
    messages=[{
        "role": "user",
        "content": "Hello"
    }],
)
answer = resp["message"]["content"]
```

  </div>
  </v-click>
  <v-click>
  <div class="p-4 border border-green-500 rounded-lg bg-green-900/10">
    <div class="font-bold text-green-400 mb-2">âœ… Now (Day 3 â€” Remote GPU)</div>

```python
resp = chat_client.chat.completions.create(
    model=CHAT_MODEL,
    messages=[{
        "role": "user",
        "content": "Hello"
    }],
)
answer = resp.choices[0].message.content
```

  </div>
  </v-click>
</div>

<v-click>
<div class="mt-6 p-3 border border-yellow-500 rounded-lg bg-yellow-900/20 text-center text-sm">
  Same idea, different syntax: <code>chat_client.chat.completions.create()</code> + <code>.choices[0].message.content</code>
</div>
</v-click>

<!--
**How to Call the Remote LLM (3 mins)**

- Left: What you used in Part 3 â€” ollama.chat() with local model
- Right: What you'll use today â€” OpenAI-compatible client pointing to Modal GPU
- Key differences:
  - chat_client.chat.completions.create() instead of ollama.chat()
  - .choices[0].message.content instead of ["message"]["content"]
  - Model is 8B params on GPU â€” much faster and more capable
- Everything else is the same: messages list, role/content format

å»£æ±è©±ï¼š
- å·¦é‚Šï¼šPart 3 ç”¨å˜… â€” `ollama.chat()` é… local model
- å³é‚Šï¼šä»Šæ—¥æœƒç”¨å˜… â€” OpenAI-compatible client æŒ‡å‘ Modal GPU
- é—œéµåˆ†åˆ¥ï¼š
  - ç”¨ `chat_client.chat.completions.create()` å–ä»£ `ollama.chat()`
  - ç”¨ `.choices[0].message.content` å–ä»£ `["message"]["content"]`
  - Model ä¿‚ GPU ä¸Šå˜… 8B params â€” å¿«å¥½å¤šåŒå‹å¥½å¤š
- å…¶ä»–å˜¢ä¸€æ¨£ï¼šmessages list, role/content æ ¼å¼ä¸è®Š
-->

---
layout: center
---

# How to Use the Reranker

```python
# Rerank 10 documents, keep top 3
reranked = _rerank(
    query="What is the procedure for Level 3 Alarm?",
    documents=["doc1 text...", "doc2 text...", ...],
    top_k=3
)
# Returns: [("most relevant doc", 0.72), ("second best", 0.61), ...]
```

<v-click>
<div class="grid grid-cols-2 gap-8 mt-6 text-sm">
  <div class="p-4 border border-blue-500 rounded-lg">
    <div class="font-bold text-blue-400 mb-2">ğŸ” Use 1: Filtering</div>
    <div class="text-xs">Keep only high-scoring results before generation</div>

```python
results = [doc for doc, score in reranked
           if score > 0.3]
```

  </div>
  <div class="p-4 border border-yellow-500 rounded-lg">
    <div class="font-bold text-yellow-400 mb-2">âš–ï¸ Use 2: Grading (CRAG)</div>
    <div class="text-xs">Check if docs are relevant enough</div>

```python
best_score = reranked[0][1]
if best_score < 0.5:
    rewrite_and_retry()
```

  </div>
</div>
</v-click>

<v-click>
<div class="mt-4 text-center text-xs opacity-75">
  Scores: 0â€“1 range | >0.5 = relevant | <0.3 = irrelevant
</div>
</v-click>

<!--
**How to Use the Reranker (3 mins)**

- _rerank() is a wrapper we provide â€” handles the HTTP call to Modal GPU
- Input: query string + list of document texts + how many to keep
- Output: list of (document_text, relevance_score) tuples, sorted by score
- Two use cases:
  1. Filtering: Keep only high-scoring results before feeding to LLM
  2. Grading: In CRAG, check if best_score >= threshold to decide whether to retry
- Scores are 0-1 with clear separation: relevant ~0.6-0.7, irrelevant ~0.2

å»£æ±è©±ï¼š
- `_rerank()` ä¿‚æˆ‘å“‹æä¾›å˜… wrapper â€” å¹«ä½ ææ‚å» Modal GPU å˜… HTTP call
- è¼¸å…¥ï¼šquery string + document texts list + è¦ç•™å¹¾å¤šå€‹
- è¼¸å‡ºï¼š(document_text, relevance_score) tuples listï¼ŒæŒ‰åˆ†æ•¸æ’å¥½
- å…©å€‹ç”¨é€”ï¼š
  1. Filteringï¼šä¿¾ LLM ä¹‹å‰ï¼Œåªç•™é«˜åˆ†çµæœ
  2. Gradingï¼šå–º CRAG å…¥é¢ï¼Œcheck ä¸‹ best_score >= threshold åšŸæ±ºå®šéœ€å””éœ€è¦ retry
- åˆ†æ•¸ä¿‚ 0-1ï¼šrelevant å¤§ç´„ 0.6-0.7ï¼Œirrelevant å¤§ç´„ 0.2ï¼Œåˆ†å¾—å¥½é–‹
-->



---
layout: center
---

# The Assumption We Made

<div class="text-8xl mb-8">ğŸ¤”</div>

<v-click>
<div class="text-xl mb-6">
  Our pipeline assumes the <span class="text-red-400 font-bold">query is perfect</span>
</div>
</v-click>

<v-click>
<div class="grid grid-cols-3 gap-6 text-center text-sm">
  <div class="p-4 border border-red-500 rounded-lg bg-red-900/20">
    <div class="text-2xl mb-2">âŒ</div>
    <div class="font-bold text-red-400">Bad Query</div>
    <div class="text-xs opacity-75 mt-1">"Lost ID card"</div>
    <div class="text-xs opacity-50">vs "Identification Document Replacement"</div>
  </div>
  <div class="p-4 border border-red-500 rounded-lg bg-red-900/20">
    <div class="text-2xl mb-2">âŒ</div>
    <div class="font-bold text-red-400">Bad Retrieval</div>
    <div class="text-xs opacity-75 mt-1">Found Level 2 docs</div>
    <div class="text-xs opacity-50">when asking about Level 3</div>
  </div>
  <div class="p-4 border border-red-500 rounded-lg bg-red-900/20">
    <div class="text-2xl mb-2">âŒ</div>
    <div class="font-bold text-red-400">Bad Answer</div>
    <div class="text-xs opacity-75 mt-1">First draft misses nuances</div>
    <div class="text-xs opacity-50">in complex policy questions</div>
  </div>
</div>
</v-click>

<!--
**The Assumption We Made (3 mins)**

- Everything we built assumes the user writes a perfect query
- Reality: Three failure modes
  1. Bad Query: User says "lost ID" but document says "Identification Document Replacement Procedure"
  2. Bad Retrieval: System finds wrong documents (Level 2 instead of Level 3 alarm procedures)
  3. Bad Answer: LLM generates incomplete or unfaithful answer on first try
- Each failure mode has a specific advanced RAG technique to fix it
- That's what today is about: building systems that handle imperfect inputs

å»£æ±è©±ï¼š
- æˆ‘å“‹ä¹‹å‰èµ·å˜…å˜¢ï¼Œå…¨éƒ¨å‡è¨­ç”¨æˆ¶æœƒå¯«ä¸€å€‹å®Œç¾ query
- ç¾å¯¦ï¼šä¸‰ç¨®å¤±æ•—æ¨¡å¼
  1. Bad Queryï¼šç”¨æˆ¶è©± "lost ID" ä½†æ–‡ä»¶å¯« "Identification Document Replacement Procedure"
  2. Bad Retrievalï¼šç³»çµ±æµéŒ¯æ–‡ä»¶ (å• Level 3 alarm ä½†æµå’— Level 2 docs)
  3. Bad Answerï¼šLLM ç¬¬ä¸€è½‰ç”Ÿæˆå˜…ç­”æ¡ˆå””å®Œæ•´æˆ–è€…å””æº–ç¢º
- æ¯ä¸€ç¨®å¤±æ•—æ¨¡å¼éƒ½æœ‰ç‰¹å®šå˜… Advanced RAG æŠ€è¡“å»æ•‘
- ä»Šæ—¥å°±ä¿‚è¬›å‘¢æ¨£ï¼šèµ·ä¸€å€‹è­˜è™•ç†ã€Œä¸å®Œç¾è¼¸å…¥ã€å˜…ç³»çµ±
-->

---
layout: center
---

# The Problem: Vocabulary Mismatch

<div class="grid grid-cols-2 gap-12">
  <v-click>
  <div class="p-6 border-2 border-red-500 rounded-xl bg-red-900/20">
    <div class="text-3xl mb-4">ğŸ‘¤</div>
    <div class="text-xl font-bold text-red-400">"å””è¦‹å’—å¼µèº«ä»½è­‰"</div>
    <div class="text-sm opacity-75 mt-3">å»£æ±è©±å£èª</div>
    <div class="text-sm opacity-75">Short / Vague</div>
    <div class="text-sm opacity-75">Ambiguous intent</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-6 border-2 border-blue-500 rounded-xl bg-blue-900/20">
    <div class="text-3xl mb-4">ğŸ“‹</div>
    <div class="text-xl font-bold text-blue-400">"è£œé ˜èº«ä»½è­‰æ˜æ–‡ä»¶ç¨‹åº"</div>
    <div class="text-sm opacity-75 mt-3">å®˜æ–¹æ›¸é¢èª</div>
    <div class="text-sm opacity-75">Formal language</div>
    <div class="text-sm opacity-75">Specific procedures</div>
  </div>
  </v-click>
</div>

<v-click>
<div class="mt-8 text-center text-xl text-yellow-400">
  Even vector search struggles when the semantic gap is too wide ğŸ“‰
</div>
</v-click>

<!--
**Vocabulary Mismatch (3 mins)**

- Government scenario: Public inquiry chatbot
- Citizens use Cantonese slang: "å””è¦‹å’—å¼µèº«ä»½è­‰", "éš”é›¢å¤ªå˜ˆ", "æŠ„å’—ç‰Œ"
- Official docs use formal written Chinese: "è£œé ˜èº«ä»½è­‰æ˜æ–‡ä»¶ç¨‹åº", "å™ªéŸ³æ»‹æ“¾æ¢ä¾‹", "å®šé¡ç½°æ¬¾é€šçŸ¥æ›¸"
- Even vector search can fail when the semantic distance is too far
- We need to translate "User Language" to "System Language" BEFORE we search

å»£æ±è©±ï¼š
- æ”¿åºœå ´æ™¯ï¼šå…¬çœ¾æŸ¥è©¢ Chatbot
- å¸‚æ°‘ç”¨å»£æ±è©±å£èªï¼š"å””è¦‹å’—å¼µèº«ä»½è­‰", "éš”é›¢å¤ªå˜ˆ", "æŠ„å’—ç‰Œ"
- å®˜æ–¹æ–‡ä»¶ç”¨æ›¸é¢èªï¼š"è£œé ˜èº«ä»½è­‰æ˜æ–‡ä»¶ç¨‹åº", "å™ªéŸ³æ»‹æ“¾æ¢ä¾‹", "å®šé¡ç½°æ¬¾é€šçŸ¥æ›¸"
- ç•¶èªç¾©è·é›¢å¤ªé ï¼Œå°±ç®— Vector search éƒ½æœƒå¤±æ•—
- æˆ‘å“‹éœ€è¦å–ºæœå°‹ **ä¹‹å‰**ï¼Œå°‡ã€Œç”¨æˆ¶èªè¨€ã€ç¿»è­¯æˆã€Œç³»çµ±èªè¨€ã€
-->

---
layout: center
---

# 5 Techniques to Fix This

<div class="grid grid-cols-5 gap-3 text-center text-xs">
  <v-click>
  <div class="p-3 border border-blue-500 rounded-lg">
    <div class="text-2xl mb-2">ğŸ”€</div>
    <div class="font-bold text-blue-400">Multi-Query</div>
    <div class="opacity-75 mt-1">Cast a wider net</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-3 border border-green-500 rounded-lg">
    <div class="text-2xl mb-2">ğŸŒ‰</div>
    <div class="font-bold text-green-400">HyDE</div>
    <div class="opacity-75 mt-1">Semantic bridge</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-3 border border-yellow-500 rounded-lg">
    <div class="text-2xl mb-2">ğŸš¦</div>
    <div class="font-bold text-yellow-400">Modular RAG</div>
    <div class="opacity-75 mt-1">Smart routing</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-3 border border-red-500 rounded-lg">
    <div class="text-2xl mb-2">ğŸ”„</div>
    <div class="font-bold text-red-400">CRAG</div>
    <div class="opacity-75 mt-1">Self-correction</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-3 border border-purple-500 rounded-lg">
    <div class="text-2xl mb-2">ğŸª</div>
    <div class="font-bold text-purple-400">Self-RAG</div>
    <div class="opacity-75 mt-1">Draft â†’ Reflect</div>
  </div>
  </v-click>
</div>

<v-click>
<div class="mt-8 text-center text-sm opacity-75">
  Each fixes a different failure mode. Let's explore them one by one.
</div>
</v-click>

<!--
**5 Techniques Overview (2 mins)**

- Quick preview of what's coming â€” don't explain details yet
- Multi-Query: Fix bad queries by generating variants
- HyDE: Fix semantic gap by generating fake answers
- Modular RAG: Route different query types to different strategies
- CRAG: Detect bad retrieval and retry
- Self-RAG: Detect bad answers and improve
- Each technique addresses a specific failure mode

å»£æ±è©±ï¼š
- å¿«é€Ÿé è¦½ä¸€é™£æœƒè¬›å˜…å˜¢ â€” å””æ´—è¬›ç´°ç¯€ä½
- Multi-Queryï¼šç”Ÿæˆè®Šé«”ï¼Œä¿®æ­£çˆ› queries
- HyDEï¼šç”Ÿæˆå‡ç­”æ¡ˆï¼Œä¿®æ­£èªç¾©é´»æº
- Modular RAGï¼šå°‡å””åŒ query è·¯ç”±å»å””åŒç­–ç•¥
- CRAGï¼šæª¢æ¸¬çˆ› retrieval ç„¶å¾Œ retry
- Self-RAGï¼šæª¢æ¸¬çˆ› answer ç„¶å¾Œæ”¹å–„
- æ¯ä¸€ç¨®æŠ€è¡“éƒ½ä¿‚é‡å°ä¸€ç¨®ç‰¹å®šå˜…å¤±æ•—æ¨¡å¼
-->

---
layout: center
---

# Technique 1: Multi-Query Expansion

<div class="text-xl mb-4">Solve ambiguity by <span class="text-blue-400 font-bold">casting a wider net</span></div>

<Transform :scale="1.0" origin="center">

```mermaid
flowchart LR
    Q[â“ Query] --> LLM[ğŸ¤– LLM]
    LLM --> V1[Variant 1]
    LLM --> V2[Variant 2]
    LLM --> V3[Variant 3]
    V1 --> S1[ğŸ” Search]
    V2 --> S2[ğŸ” Search]
    V3 --> S3[ğŸ” Search]
    S1 --> RRF[ğŸ”— RRF Merge]
    S2 --> RRF
    S3 --> RRF

    style Q fill:#3b82f6,color:#fff
    style LLM fill:#a855f7,color:#fff
    style S1 fill:#22c55e,color:#000
    style S2 fill:#22c55e,color:#000
    style S3 fill:#22c55e,color:#000
    style RRF fill:#eab308,color:#000
```

</Transform>

<v-click>
<div class="mt-6 p-3 border border-blue-500 rounded-lg bg-blue-900/20 text-center text-sm">
  ğŸ’¡ <em>Like asking 3 colleagues to Google the same thing â€” each uses different words, together they find everything</em>
</div>
</v-click>

<v-click>
<div class="mt-2 p-3 border border-cyan-500 rounded-lg bg-cyan-900/20 text-xs">
  ğŸ”¬ <strong class="text-cyan-400">Why it works:</strong> Embedding is <em>lossy compression</em> â€” one query compresses to one point, but your concept has many facets. Each variant emphasizes a different facet. RRF rewards documents that appear across multiple angles.
</div>
</v-click>

<!--
**Multi-Query Expansion (4 mins)**

- Analogy: 3 colleagues searching = 3 query variants. Different words, same intent, better coverage.
- THE REAL INSIGHT: Embedding is lossy compression. "Lost ID" compresses to ONE point in vector space, but the concept has multiple facets â€” the replacement procedure, the reporting process, the fee schedule. Each variant query emphasizes a different facet, so each search finds documents from a different angle.
- Why RRF matters here: RRF rewards documents that appear across multiple search results. A document that shows up for 3 different query variants is almost certainly relevant â€” it covers the concept comprehensively, not just one angle.
- Breadth strategy: Multi-Query casts a WIDE NET. Each individual search still has the query-document asymmetry problem, but together they cover more ground.
- Process: User query â†’ LLM generates 3 variants â†’ Search ALL 4 â†’ Fuse with RRF (from Day 2!)
- Key: Reuses your _hybrid_search() and RRF from Part 3
- vs HyDE: Multi-Query = breadth (3 questions, 3 searches). HyDE = depth (1 fake document, 1 search, sharper probe). They're complementary â€” Path A combines both.

å»£æ±è©±ï¼š
- æ¯”å–»ï¼šæµ 3 å€‹åŒäº‹ä¸€é½Š Google = 3 å€‹ query è®Šé«”ã€‚å””åŒå­—çœ¼ï¼ŒåŒä¸€æ„åœ–ï¼Œè¦†è“‹ç‡æ›´é«˜ã€‚
- çœŸæ­£å˜…æ´è¦‹ï¼šEmbedding ä¿‚æœ‰æå£“ç¸®ã€‚"éºå¤±èº«ä»½è­‰" å£“ç¸®æˆå‘é‡ç©ºé–“å…¥é¢ä¸€å€‹é»ï¼Œä½†å‘¢å€‹æ¦‚å¿µæœ‰å¥½å¤šé¢ â€” è£œé ˜ç¨‹åºã€å ±å¤±æµç¨‹ã€è²»ç”¨ã€‚æ¯å€‹è®Šé«” query å¼·èª¿å””åŒå˜…é¢ï¼Œæ‰€ä»¥æ¯æ¬¡ search æµåˆ°å””åŒè§’åº¦å˜…æ–‡ä»¶ã€‚
- é»è§£ RRF å–ºåº¦é‡è¦ï¼šRRF çå‹µå‡ºç¾å–ºå¤šå€‹æœå°‹çµæœå˜…æ–‡ä»¶ã€‚ä¸€ä»½æ–‡ä»¶å¦‚æœ 3 å€‹å””åŒ query è®Šé«”éƒ½æµåˆ°ä½¢ï¼Œå¹¾ä¹è‚¯å®šä¿‚ç›¸é—œå˜… â€” ä½¢å…¨é¢è¦†è“‹å€‹æ¦‚å¿µï¼Œå””æ­¢ä¸€å€‹è§’åº¦ã€‚
- é—Šåº¦ç­–ç•¥ï¼šMulti-Query æ’’å¤§ç¶²ã€‚æ¯å€‹å–®ç¨å˜… search ä»ç„¶æœ‰ query-document ä¸å°ç¨±å•é¡Œï¼Œä½†åŠ åŸ‹ä¸€é½Šå°±è¦†è“‹æ›´å¤šç¯„åœã€‚
- æµç¨‹ï¼šUser query â†’ LLM ç”Ÿæˆ 3 å€‹è®Šé«” â†’ 4 å€‹ä¸€é½Š Search â†’ ç”¨ RRF èåˆ (Day 2 å­¸éï¼)
- é—œéµï¼šé‡ç”¨ä½  Part 3 å˜… `_hybrid_search()` åŒ RRF
- åŒ HyDE æ¯”è¼ƒï¼šMulti-Query = é—Šåº¦ (3 æ¢å•é¡Œï¼Œ3 æ¬¡ search)ã€‚HyDE = æ·±åº¦ (1 ä»½å‡æ–‡ä»¶ï¼Œ1 æ¬¡ searchï¼Œæ›´ç²¾æº–å˜…æ¢é‡)ã€‚ä½¢å“‹äº’è£œ â€” Path A å…©å€‹éƒ½ç”¨ã€‚
-->

---
layout: center
---

# Multi-Query: Government Scenario

<div class="text-5xl mb-6">ğŸ›ï¸</div>

<div class="text-lg mb-4"><span class="text-blue-400">Scenario:</span> Public Inquiry Chatbot</div>

<v-click>
<div class="p-4 border border-blue-500 rounded-lg bg-blue-900/20 mb-4">
  <div class="font-bold text-blue-400">User asks:</div>
  <div class="text-xl">"Lost ID card"</div>
</div>
</v-click>

<v-click>
<div class="p-4 border border-purple-500 rounded-lg bg-purple-900/20 mb-4">
  <div class="font-bold text-purple-400">LLM generates 3 variants:</div>
  <div class="text-sm mt-2">1. "How to replace HKID card"</div>
  <div class="text-sm">2. "Report lost identification document procedure"</div>
  <div class="text-sm">3. "Fee for new identity card application"</div>
</div>
</v-click>

<v-click>
<div class="p-4 border border-green-500 rounded-lg bg-green-900/20">
  <div class="font-bold text-green-400">Result:</div>
  <div class="text-sm">4 searches â†’ RRF fusion â†’ covers formal AND informal terminology âœ…</div>
</div>
</v-click>

<!--
**Multi-Query Government Scenario (2 mins)**

- Public inquiry chatbot: citizens use unpredictable terminology
- "Lost ID" is too vague for BM25 and too short for good vector embeddings
- Multi-Query generates variants that cover different angles
- RRF fusion (from Day 2) merges all results democratically
- Best for: citizen-facing systems, FAQ chatbots, general inquiry portals
- Document types: public-facing guidelines, FAQ documents, service procedures

å»£æ±è©±ï¼š
- å…¬çœ¾æŸ¥è©¢ Chatbotï¼šå¸‚æ°‘ç”¨è©å¥½é›£é è¨ˆ
- "Lost ID" å° BM25 åšŸè¬›å¤ªå«ç³Šï¼Œå° Vector åšŸè¬›å¤ªçŸ­
- Multi-Query ç”Ÿæˆè¦†è“‹å””åŒè§’åº¦å˜…è®Šé«”
- RRF èåˆ (Day 2) æ°‘ä¸»åœ° merge åŸ‹å•²çµæœ
- æœ€é©åˆï¼šå°å¸‚æ°‘ç³»çµ±ã€FAQ chatbotsã€ä¸€èˆ¬æŸ¥è©¢ portal
- æ–‡ä»¶é¡å‹ï¼šå…¬çœ¾æŒ‡å¼•ã€FAQ æ–‡ä»¶ã€æœå‹™ç¨‹åº
-->

---
layout: center
---

# Technique 2: HyDE

<div class="text-xl mb-4">Hypothetical Document Embeddings â€” a <span class="text-green-400 font-bold">semantic bridge</span></div>

<div class="grid grid-cols-2 gap-8 text-center mb-4">
  <v-click>
  <div class="p-4 border border-red-500 rounded-lg bg-red-900/10">
    <div class="font-bold text-red-400">âŒ Standard RAG</div>
    <div class="text-xs mt-2">Embed(<span class="text-blue-400">"Evidence handling rules?"</span>)</div>
    <div class="text-xs mt-1 opacity-75">3 words â†’ <span class="text-red-400">vague, ambiguous</span> vector</div>
    <div class="text-xs mt-1 opacity-50">Could mean: collection? storage? court submission?</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-4 border border-green-500 rounded-lg bg-green-900/10">
    <div class="font-bold text-green-400">âœ… HyDE</div>
    <div class="text-xs mt-2">Embed(<span class="text-purple-400">"Officers shall maintain chain of custody..."</span>)</div>
    <div class="text-xs mt-1 opacity-75">70 words â†’ <span class="text-green-400">specific, domain-rich</span> vector</div>
    <div class="text-xs mt-1 opacity-50">Disambiguated + right vocabulary</div>
  </div>
  </v-click>
</div>

<Transform :scale="1.0" origin="center">

```mermaid
flowchart LR
    Q[â“ Query] --> GEN[ğŸ¤– Generate\nFake Answer]
    GEN --> EMB[ğŸ§  Embed\nFake Answer]
    EMB --> VEC[ğŸ” Vector\nSearch]
    VEC --> REAL[ğŸ“„ Real Docs]

    style Q fill:#3b82f6,color:#fff
    style GEN fill:#a855f7,color:#fff
    style EMB fill:#eab308,color:#000
    style VEC fill:#22c55e,color:#000
    style REAL fill:#6b7280,color:#fff
```

</Transform>

<v-click>
<div class="mt-4 p-3 border border-green-500 rounded-lg bg-green-900/20 text-center text-sm">
  ğŸ’¡ <em>You're in a massive library. You ask: "evidence?" The librarian vaguely gestures at 3 sections. But if you say: "I need the procedure for maintaining chain of custody when collecting physical evidence at crime scenes" â€” the librarian walks you straight to the right shelf.</em>
</div>
</v-click>

<v-click>
<div class="mt-2 p-3 border border-cyan-500 rounded-lg bg-cyan-900/20 text-xs">
  ğŸ”¬ <strong class="text-cyan-400">Why it works:</strong> The fake answer <em>disambiguates</em> your intent and introduces <em>domain vocabulary</em> ("chain of custody", "exhibit label", "forensic integrity"). It doesn't need to be correct â€” just <strong>specific</strong>. We use its embedding as a search probe, then throw it away.
</div>
</v-click>

<!--
**HyDE (5 mins)**

- Analogy: Library analogy â€” "evidence?" gets a vague gesture at 3 sections. "I need the procedure for maintaining chain of custody when collecting physical evidence at crime scenes" gets you walked to the right shelf. HyDE turns a vague gesture into a specific description.
- THE REAL INSIGHT: It's NOT that embeddings are broken. Same model, same dimensions, semantic search works. The issue is QUERY-DOCUMENT ASYMMETRY + INFORMATION SPARSITY.
- Queries are information-sparse and ambiguous: "Evidence handling rules?" â€” 3 words. The embedding model compresses this into a single vector, but those 3 words could mean collection procedures, storage requirements, court submission protocols, or forensic lab standards. The resulting vector is a BLURRY AVERAGE of all possible intents.
- The fake answer helps because it's SPECIFIC, not because it's correct:
  1. DISAMBIGUATES intent â€” commits to one interpretation (the collection procedure)
  2. INTRODUCES DOMAIN VOCABULARY â€” "chain of custody", "exhibit label", "tamper-evident bag", "forensic integrity" â€” the exact words in real documents
  3. MATCHES DOCUMENT REGISTER â€” reads like a policy document, not a question
- The embedding of the fake answer is a SHARPER, MORE SPECIFIC probe. It collapses ambiguity into a specific point closer to the right documents.
- Critical: We THROW AWAY the fake answer's content. We only use its embedding as a search probe. The final answer comes from REAL documents + ORIGINAL query.
- vs Multi-Query: HyDE = depth (1 fake document, 1 search, precise spear). Multi-Query = breadth (3 questions, 3 searches, wide net). They're complementary.
- Uses local embeddings (ollama.embed) â€” only the generation is remote

å»£æ±è©±ï¼š
- æ¯”å–»ï¼šåœ–æ›¸é¤¨æ¯”å–» â€” ä½ å•ã€Œè­‰ç‰©ï¼Ÿã€ç®¡ç†å“¡å«ç³Šå’æŒ‡ä¸‰å€‹æ–¹å‘ã€‚ä½†å¦‚æœä½ è¬›ã€Œæˆ‘è¦æµé—œæ–¼å–ºæ¡ˆç™¼ç¾å ´æ”¶é›†å¯¦ç‰©è­‰æ“šæ™‚ç¶­æŒè­‰ç‰©éˆå˜…ç¨‹åºã€â€” ç®¡ç†å“¡ç›´æ¥å¸¶ä½ å»å•±å˜…æ›¸æ¶ã€‚HyDE å°‡å«ç³Šå˜…æ‰‹å‹¢è®Šæˆå…·é«”å˜…æè¿°ã€‚
- çœŸæ­£å˜…æ´è¦‹ï¼šå””ä¿‚ embedding å£å’—ã€‚åŒä¸€å€‹ modelï¼ŒåŒä¸€å€‹ç¶­åº¦ï¼Œèªç¾©æœå°‹ä¿‚ work å˜…ã€‚å•é¡Œä¿‚ QUERY-DOCUMENT ä¸å°ç¨± + è³‡è¨Šç¨€ç–ã€‚
- Query è³‡è¨Šç¨€ç–åˆå«ç³Šï¼š"è­‰ç‰©è™•ç†è¦å‰‡ï¼Ÿ" â€” 3 å€‹å­—ã€‚Embedding model è¦å°‡å‘¢ 3 å€‹å­—å£“ç¸®æˆä¸€å€‹å‘é‡ï¼Œä½†å‘¢ 3 å€‹å­—å¯ä»¥æŒ‡æ”¶é›†ç¨‹åºã€å„²å­˜è¦æ±‚ã€å‘ˆå ‚ç¨‹åºã€æˆ–è€…é‘‘è­‰åŒ–é©—æ¨™æº–ã€‚çµæœå˜…å‘é‡ä¿‚æ‰€æœ‰å¯èƒ½æ„åœ–å˜…æ¨¡ç³Šå¹³å‡å€¼ã€‚
- å‡ç­”æ¡ˆæœ‰ç”¨ä¿‚å› ç‚ºä½¢å¤ å…·é«”ï¼Œå””ä¿‚å› ç‚ºä½¢æ­£ç¢ºï¼š
  1. æ¶ˆé™¤æ­§ç¾© â€” é–å®šä¸€å€‹è§£è®€ï¼ˆæ”¶é›†ç¨‹åºï¼‰
  2. å¼•å…¥é ˜åŸŸè©å½™ â€” "è­‰ç‰©éˆ"ã€"è­‰ç‰©æ¨™ç±¤"ã€"é˜²æ‹†å°è¢‹"ã€"é‘‘è­‰å®Œæ•´æ€§" â€” çœŸæ­£æ–‡ä»¶å…¥é¢å˜…å­—
  3. åŒ¹é…æ–‡ä»¶èªåŸŸ â€” è®€èµ·åšŸä¼¼æ”¿ç­–æ–‡ä»¶ï¼Œå””ä¼¼å•é¡Œ
- å‡ç­”æ¡ˆå˜… embedding ä¿‚ä¸€å€‹æ›´ç²¾æº–ã€æ›´å…·é«”å˜…æ¢é‡ã€‚ä½¢å°‡æ¨¡ç³Šæ€§æ”¶çª„åˆ°ä¸€å€‹æ›´æ¥è¿‘æ­£ç¢ºæ–‡ä»¶å˜…å…·é«”é»ã€‚
- é—œéµï¼šæˆ‘å“‹ä¸Ÿæ£„å‡ç­”æ¡ˆå˜…å…§å®¹ã€‚åªç”¨ä½¢å˜… embedding åšæœå°‹æ¢é‡ã€‚æœ€çµ‚ç­”æ¡ˆä¾†è‡ªçœŸæ­£æ–‡ä»¶ + åŸå§‹ queryã€‚
- åŒ Multi-Query æ¯”è¼ƒï¼šHyDE = æ·±åº¦ (1 ä»½å‡æ–‡ä»¶ï¼Œ1 æ¬¡ searchï¼Œç²¾æº–å˜…çŸ›)ã€‚Multi-Query = é—Šåº¦ (3 æ¢å•é¡Œï¼Œ3 æ¬¡ searchï¼Œå¤§ç¶²)ã€‚ä½¢å“‹äº’è£œã€‚
- ç”¨æœ¬åœ° embeddingï¼ˆollama.embedï¼‰â€” åªæœ‰ç”Ÿæˆéƒ¨åˆ†ç”¨é ç«¯ GPU
-->

---
layout: two-cols
---

# HyDE: Step-by-Step Trace

```python {all|1|2-6|7|8}
query = "What are the evidence handling rules?"
resp = chat_client.chat.completions.create(
    model=CHAT_MODEL,
    messages=[{"role": "user",
      "content": f"Answer: {query}"}],
)
fake_answer = resp.choices[0].message.content
hyde_vec = ollama.embed(model=EMBED_MODEL,
                        input=fake_answer)
results = _search_vector(conn, hyde_vec, limit=5)
answer = _generate_answer(query, results)
```

<div class="mt-3 p-2 border border-red-500 rounded bg-red-900/20 text-xs">
  âš ï¸ <code>fake_answer</code> is a <strong>search probe</strong> â€” we throw it away after embedding
</div>

::right::

<div class="pl-6 pt-4">

<v-click at="0">
<div class="mb-2 p-2 bg-blue-900/30 rounded border border-blue-500">
  <div class="text-xs opacity-75">â“ User Query (6 words):</div>
  <code class="text-xs">"What are the evidence handling rules?"</code>
  <div class="text-xs text-red-400 mt-1">âš ï¸ Ambiguous: collection? storage? court submission?</div>
</div>
</v-click>

<v-click at="1">
<div class="mb-2 p-2 bg-purple-900/30 rounded border border-purple-500">
  <div class="text-xs opacity-75">ğŸ¤– Fake Answer (~70 words):</div>
  <div class="text-xs mt-1">"Evidence must be collected following strict <span class="text-purple-400">chain of custody</span> procedures. Each item shall be placed in a <span class="text-purple-400">tamper-evident bag</span> with an <span class="text-purple-400">exhibit label</span> recording the officer, date, time, and location of recovery..."</div>
  <div class="text-xs text-yellow-400 mt-1">âš¡ May be wrong â€” doesn't matter!</div>
</div>
</v-click>

<v-click at="2">
<div class="mb-2 p-2 bg-yellow-900/30 rounded border border-yellow-500">
  <div class="text-xs opacity-75">ğŸ§  Embed fake answer (not query!):</div>
  <div class="text-xs mt-1">Vector encodes: "chain of custody", "tamper-evident", "exhibit label", "forensic integrity", "Standing Order"...</div>
  <div class="text-xs text-green-400 mt-1">10Ã— more vocabulary than original query</div>
</div>
</v-click>

<v-click at="3">
<div class="mb-2 p-2 bg-green-900/30 rounded border border-green-500">
  <div class="text-xs opacity-75">ğŸ“„ Search results (real documents!):</div>
  <div class="text-xs mt-1">1. Standing Order 18-02: Evidence Collection <span class="text-green-400">(0.87)</span></div>
  <div class="text-xs">2. Forensic Evidence Handling Guide <span class="text-green-400">(0.82)</span></div>
  <div class="text-xs">3. Exhibit Management Procedures <span class="text-green-400">(0.76)</span></div>
</div>
</v-click>

</div>

<!--
**HyDE Step-by-Step Trace (3 mins)**

- Walk through the code left, data right â€” same format as Day 1's keyword search trace
- Line 1: The user's query â€” only 6 words, colloquial, ambiguous
- Lines 2-6: Send to remote GPU LLM to generate a fake answer. The prompt is simple: "Answer: {query}"
- Line 7: Extract the fake answer â€” ~70 words of policy-style text. Highlight the domain vocabulary in purple: "chain of custody", "tamper-evident bag", "exhibit label"
- Line 8: Embed the FAKE ANSWER locally (not the query!). This vector has 10Ã— more relevant vocabulary than the original 6-word query
- Line 9: Search with the fake answer's embedding â€” finds the actual policy documents with high scores
- Line 10: Generate final answer from REAL documents using the ORIGINAL query
- KEY POINT: The fake answer might be factually wrong. We don't care â€” we only used its embedding as a search probe. The real documents are what matter.
- Compare: Standard RAG would embed "What are the evidence handling rules?" (6 words) â†’ vague vector â†’ misses the policy documents

å»£æ±è©±ï¼š
- å·¦é‚Šè¡Œ codeï¼Œå³é‚Šè¡Œ data â€” åŒ Day 1 keyword search trace ä¸€æ¨£å˜…æ ¼å¼
- Line 1ï¼šç”¨æˆ¶å˜… query â€” å¾— 6 å€‹å­—ï¼Œå£èªåŒ–ï¼Œå«ç³Š
- Lines 2-6ï¼šSend å»é ç«¯ GPU LLM ç”Ÿæˆå‡ç­”æ¡ˆã€‚Prompt å¥½ç°¡å–®ï¼š"Answer: {query}"
- Line 7ï¼šæ”å‡ºå‡ç­”æ¡ˆ â€” å¤§ç´„ 70 å­—å˜…æ”¿ç­–é¢¨æ ¼æ–‡å­—ã€‚ç•™æ„ç´«è‰²å˜…é ˜åŸŸè©å½™ï¼š"è­‰ç‰©éˆ"ã€"é˜²æ‹†å°è¢‹"ã€"è­‰ç‰©æ¨™ç±¤"
- Line 8ï¼šå–ºæœ¬åœ° embed å‡ç­”æ¡ˆï¼ˆå””ä¿‚ queryï¼ï¼‰ã€‚å‘¢å€‹å‘é‡æœ‰æ¯”åŸæœ¬ 6 å€‹å­— query å¤š 10 å€å˜…ç›¸é—œè©å½™
- Line 9ï¼šç”¨å‡ç­”æ¡ˆå˜… embedding åš search â€” æµåˆ°çœŸæ­£å˜…æ”¿ç­–æ–‡ä»¶ï¼Œåˆ†æ•¸å¥½é«˜
- Line 10ï¼šç”¨çœŸæ­£æ–‡ä»¶ + åŸå§‹ query ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ
- é‡é»ï¼šå‡ç­”æ¡ˆå¯èƒ½äº‹å¯¦ä¸Šä¿‚éŒ¯å˜…ã€‚æˆ‘å“‹å”” care â€” æˆ‘å“‹åªä¿‚ç”¨ä½¢å˜… embedding åšæœå°‹æ¢é‡ã€‚çœŸæ­£å˜…æ–‡ä»¶å…ˆä¿‚é‡è¦å˜…ã€‚
- æ¯”è¼ƒï¼šStandard RAG æœƒ embed "What are the evidence handling rules?" (6 å€‹å­—) â†’ æ¨¡ç³Šå‘é‡ â†’ miss å’—æ”¿ç­–æ–‡ä»¶
-->

---
layout: center
---

# HyDE: Government Scenario

<div class="text-5xl mb-6">ğŸ“œ</div>

<div class="text-lg mb-4"><span class="text-green-400">Scenario:</span> Abstract Policy Questions</div>

<v-click>
<div class="p-4 border border-blue-500 rounded-lg bg-blue-900/20 mb-4">
  <div class="font-bold text-blue-400">User asks:</div>
  <div class="text-xl">"Evidence handling rules?"</div>
</div>
</v-click>

<v-click>
<div class="p-4 border border-purple-500 rounded-lg bg-purple-900/20 mb-4">
  <div class="font-bold text-purple-400">LLM generates fake answer:</div>
  <div class="text-xs mt-2 italic">"All physical evidence must be collected following chain of custody procedures. Each exhibit shall be sealed in a tamper-evident bag, labelled with the officer's name, date, time, and location of recovery. Evidence must be stored in a designated secure facility..."</div>
</div>
</v-click>

<v-click>
<div class="p-4 border border-green-500 rounded-lg bg-green-900/20">
  <div class="font-bold text-green-400">Result:</div>
  <div class="text-sm">Fake answer embedding â‰ˆ Real Standing Orders embedding â†’ finds the right document âœ…</div>
</div>
</v-click>

<!--
**HyDE Government Scenario (2 mins)**

- Abstract procedural questions: "rules", "procedures", "guidelines"
- These are short queries about long, formal documents
- The fake answer reads like the actual Standing Orders document â€” same vocabulary, same formal tone
- Embedding the fake answer creates a vector in "document-land" â€” close to the real doc
- The fake answer says "chain of custody" and "tamper-evident" â€” the SAME words the real Standing Orders uses
- Even if the fake answer gets details wrong, the embedding lands in the right neighbourhood
- Best for: policy documents, Standing Orders, regulatory frameworks, compliance guidelines
- Document types: dense formal documents where concepts > keywords

å»£æ±è©±ï¼š
- æŠ½è±¡ç¨‹åºå•é¡Œï¼š"è¦å‰‡"ã€"ç¨‹åº"ã€"æŒ‡å¼•"
- å‘¢å•²ä¿‚ç”¨å¹¾éš»å­—å•é—œæ–¼å¥½é•·ã€å¥½æ­£å¼å˜…æ–‡ä»¶
- å‡ç­”æ¡ˆè®€èµ·åšŸå¥½ä¼¼çœŸæ­£å˜…ã€Šå¸¸è¡Œå‘½ä»¤ã€‹â€” åŒæ¨£å˜…è©å½™ã€åŒæ¨£å˜…æ­£å¼èªæ°£
- Embed å‡ç­”æ¡ˆä¹‹å¾Œï¼Œä½¢å˜…å‘é‡è½å–ºã€Œæ–‡ä»¶å€ã€â€” å¥½è¿‘çœŸæ­£å˜…æ–‡ä»¶
- å‡ç­”æ¡ˆç”¨å’— "è­‰ç‰©éˆ" åŒ "é˜²æ‹†å°" â€” åŒçœŸæ­£ã€Šå¸¸è¡Œå‘½ä»¤ã€‹ç”¨å˜…å­—ä¸€æ¨£
- å³ä½¿å‡ç­”æ¡ˆç´°ç¯€æœ‰éŒ¯ï¼Œembedding éƒ½æœƒè½å–ºå•±å˜…å€åŸŸ
- æœ€é©åˆï¼šæ”¿ç­–æ–‡ä»¶ã€ã€Šå¸¸è¡Œå‘½ä»¤ã€‹ã€è¦ç®¡æ¡†æ¶ã€åˆè¦æŒ‡å¼•
- æ–‡ä»¶é¡å‹ï¼šæ¦‚å¿µé‡è¦éé—œéµå­—å˜…å¯†é›†æ­£å¼æ–‡ä»¶
-->

---
layout: center
---

# Technique 3: Modular RAG (Routing)

<div class="text-xl mb-4">One size does <span class="text-yellow-400 font-bold">NOT</span> fit all</div>

<div class="grid grid-cols-3 gap-4 text-sm text-center">
  <v-click>
  <div class="p-3 border border-blue-500 rounded-lg">
    <div class="text-2xl mb-2">ğŸ”¢</div>
    <div class="font-bold text-blue-400">Factual</div>
    <div class="text-xs opacity-75">"What is the fine for littering?"</div>
    <div class="mt-2 font-mono text-xs bg-blue-900/50 p-1 rounded">â†’ BM25 (Exact Match)</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-3 border border-purple-500 rounded-lg">
    <div class="text-2xl mb-2">ğŸ§ </div>
    <div class="font-bold text-purple-400">Conceptual</div>
    <div class="text-xs opacity-75">"Explain community policing"</div>
    <div class="mt-2 font-mono text-xs bg-purple-900/50 p-1 rounded">â†’ HyDE (Semantic)</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-3 border border-yellow-500 rounded-lg">
    <div class="text-2xl mb-2">â“</div>
    <div class="font-bold text-yellow-400">Ambiguous</div>
    <div class="text-xs opacity-75">"Noise issues"</div>
    <div class="mt-2 font-mono text-xs bg-yellow-900/50 p-1 rounded">â†’ Multi-Query</div>
  </div>
  </v-click>
</div>

<v-click>
<div class="mt-6 text-center text-green-400">
  Use an LLM "Router" to pick the best strategy for each query
</div>
</v-click>

<v-click>
<div class="mt-4 p-3 border border-yellow-500 rounded-lg bg-yellow-900/20 text-center text-sm">
  ğŸ’¡ <em>Like a hospital triage nurse â€” assess the patient first, then send to the right specialist</em>
</div>
</v-click>

<v-click>
<div class="mt-2 p-3 border border-cyan-500 rounded-lg bg-cyan-900/20 text-xs">
  ğŸ”¬ <strong class="text-cyan-400">Why it works:</strong> Different query types have <em>category failures</em>. "Cap. 228 Section 14(2)" fails with vector search â€” the embedding treats "228" as a generic number. BM25 treats it as an exact token. The router prevents <strong>fundamental mismatches</strong>, not just suboptimal results.
</div>
</v-click>

<!--
**Modular RAG (4 mins)**

- Analogy: Triage nurse â†’ specialist. Don't send everyone to the same doctor.
- THE REAL INSIGHT: Different query types don't just get "slightly worse" results with the wrong strategy â€” they get CATEGORY FAILURES where the wrong search type fundamentally CANNOT find the right documents.
- Example: "Cap. 228 Section 14(2)" with vector search â€” the embedding model treats "228" and "14(2)" as generic numbers, not as specific legal identifiers. The vector lands in a vague "numbers + law" region. BM25 treats them as exact tokens and finds the exact ordinance. This isn't "BM25 is slightly better" â€” vector search CANNOT find this document.
- Reverse example: "What's the policy on community engagement?" with BM25 â€” the exact words might not appear in the document (it says "public liaison" and "neighbourhood outreach"). BM25 score: zero. Vector search understands the semantic similarity.
- The router is NOT an optimization â€” it prevents category errors where the wrong search type is fundamentally blind to what you're looking for.
- Solution: Build a Router â€” small LLM call classifies the query type, then routes to the best strategy
- This is the "architect" path â€” you design the system, not just the search

å»£æ±è©±ï¼š
- æ¯”å–»ï¼šåˆ†æµè­·å£« â†’ å°ˆç§‘é†«ç”Ÿã€‚å””å¥½å°‡æ‰€æœ‰äººéƒ½é€å»åŒä¸€å€‹é†«ç”Ÿåº¦ã€‚
- çœŸæ­£å˜…æ´è¦‹ï¼šå””åŒ query é¡å‹ç”¨éŒ¯ç­–ç•¥å””ä¿‚ã€Œå·®å°‘å°‘ã€â€” ä¿‚é¡åˆ¥æ€§å¤±æ•—ï¼ŒéŒ¯å˜… search é¡å‹æ ¹æœ¬æµå””åˆ°å•±å˜…æ–‡ä»¶ã€‚
- ä¾‹å­ï¼š"Cap. 228 Section 14(2)" ç”¨ vector search â€” embedding model å°‡ "228" åŒ "14(2)" ç•¶æˆæ™®é€šæ•¸å­—ï¼Œå””ä¿‚ç‰¹å®šæ³•å¾‹æ¨™è­˜ã€‚å€‹å‘é‡è½å–ºæ¨¡ç³Šå˜…ã€Œæ•¸å­— + æ³•å¾‹ã€å€åŸŸã€‚BM25 å°‡ä½¢å“‹ç•¶æˆç²¾ç¢º tokenï¼Œç›´æ¥æµåˆ°æ¢ä¾‹ã€‚å‘¢å€‹å””ä¿‚ã€ŒBM25 å¥½å°‘å°‘ã€â€” vector search æ ¹æœ¬æµå””åˆ°å‘¢ä»½æ–‡ä»¶ã€‚
- åé¢ä¾‹å­ï¼š"What's the policy on community engagement?" ç”¨ BM25 â€” æ–‡ä»¶å…¥é¢å¯èƒ½å¯«å˜…ä¿‚ "public liaison" åŒ "neighbourhood outreach"ã€‚BM25 åˆ†æ•¸ï¼šé›¶ã€‚Vector search ç†è§£èªç¾©ç›¸ä¼¼æ€§ã€‚
- Router å””ä¿‚å„ªåŒ– â€” ä½¢ä¿‚é˜²æ­¢é¡åˆ¥æ€§éŒ¯èª¤ï¼Œå³éŒ¯å˜… search é¡å‹å°ä½ æµå˜…å˜¢æ ¹æœ¬ä¿‚ç›²å˜…ã€‚
- è§£æ±ºæ–¹æ¡ˆï¼šèµ·ä¸€å€‹ Router â€” ç”¨ç´° LLM call å»åˆ†é¡å€‹ query typeï¼Œç„¶å¾Œè·¯ç”±å»æœ€ä½³ç­–ç•¥
- å‘¢å€‹ä¿‚ã€Œæ¶æ§‹å¸«ã€è·¯ç·š â€” ä½ ä¿‚è¨­è¨ˆå€‹ç³»çµ±ï¼Œå””æ­¢ä¿‚ search
-->

---
layout: center
---

# Modular RAG: Government Scenario

<div class="text-5xl mb-6">âš–ï¸</div>

<div class="text-lg mb-4"><span class="text-yellow-400">Scenario:</span> Multi-User Government Portal</div>

<div class="grid grid-cols-2 gap-8 text-sm">
  <v-click>
  <div class="p-4 border border-blue-500 rounded-lg">
    <div class="text-2xl mb-2">ğŸ‘¨â€âš–ï¸</div>
    <div class="font-bold text-blue-400">Legal Officer</div>
    <div class="text-xs mt-2">"Cap. 228 Section 14(2)"</div>
    <div class="text-xs opacity-75 mt-1">Needs exact Ordinance reference</div>
    <div class="mt-2 font-mono text-xs bg-blue-900/50 p-1 rounded">â†’ BM25</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-4 border border-purple-500 rounded-lg">
    <div class="text-2xl mb-2">ğŸ‘¤</div>
    <div class="font-bold text-purple-400">Citizen</div>
    <div class="text-xs mt-2">"Can I park here on Sunday?"</div>
    <div class="text-xs opacity-75 mt-1">Vague, needs interpretation</div>
    <div class="mt-2 font-mono text-xs bg-purple-900/50 p-1 rounded">â†’ Multi-Query</div>
  </div>
  </v-click>
</div>

<v-click>
<div class="mt-6 p-3 border border-green-500 rounded-lg bg-green-900/20 text-center text-sm">
  Same system, different users â†’ Router picks the right tool automatically
</div>
</v-click>

<!--
**Modular RAG Government Scenario (2 mins)**

- Government portals serve different user types with different needs
- Legal officers need exact references â€” BM25 excels at finding specific section numbers
- Citizens ask vague questions â€” Multi-Query covers different phrasings
- Policy researchers ask conceptual questions â€” HyDE bridges the semantic gap
- The Router classifies the query and picks the best strategy
- Best for: multi-user portals, systems serving both internal staff and public

å»£æ±è©±ï¼š
- æ”¿åºœ Portal æœƒæœå‹™å””åŒé¡å‹ç”¨æˆ¶ï¼Œéœ€æ±‚éƒ½å””åŒ
- Legal officers è¦ç²¾æº–å¼•ç”¨ â€” BM25 æœ€æ“…é•·æµç‰¹å®š Section number
- å¸‚æ°‘å•å«ç³Šå•é¡Œ â€” Multi-Query è¦†è“‹å””åŒè¬›æ³•
- æ”¿ç­–ç ”ç©¶å“¡å•æ¦‚å¿µæ€§å•é¡Œ â€” HyDE é€£æ¥èªç¾©é´»æº
- Router æœƒåˆ†é¡å€‹ query è‡ªå‹•æ€æœ€å¥½å˜…ç­–ç•¥
- æœ€é©åˆï¼šå¤šç”¨æˆ¶ Portalã€åŒæ™‚æœå‹™å…§éƒ¨å“¡å·¥åŒå…¬çœ¾å˜…ç³»çµ±
-->

---
layout: center
---

# Technique 4: Corrective RAG (CRAG)

<div class="text-lg mb-2">Self-correction for <span class="text-red-400 font-bold">high-stakes</span> retrieval</div>

<Transform :scale="1.0" origin="center">

```mermaid
flowchart LR
    Q[â“ Query] --> RET[ğŸ” Retrieve]
    RET --> GRADE{âš–ï¸ Grade\nReranker}
    GRADE -->|âœ… Good| GEN[ğŸ¤– Generate]
    GRADE -->|âŒ Bad| REWRITE[âœï¸ Rewrite\nQuery]
    REWRITE --> RET

    style Q fill:#3b82f6,color:#fff
    style RET fill:#22c55e,color:#000
    style GRADE fill:#eab308,color:#000
    style GEN fill:#a855f7,color:#fff
    style REWRITE fill:#ef4444,color:#fff
```

</Transform>

<v-click>
<div class="mt-4 p-3 border border-yellow-500 rounded-lg bg-yellow-900/20 text-center">
  <div class="text-yellow-400 font-bold">Key Innovation: Reranker = Grader</div>
  <div class="text-sm opacity-75">Score < 0.5 â†’ docs are irrelevant â†’ rewrite and retry</div>
</div>
</v-click>

<v-click>
<div class="mt-2 p-2 border border-red-500 rounded-lg bg-red-900/20 text-center text-sm">
  ğŸ’¡ <em>Like a quality inspector on an assembly line â€” reject bad parts, request new ones until quality passes</em>
</div>
</v-click>

<v-click>
<div class="mt-2 p-2 border border-cyan-500 rounded-lg bg-cyan-900/20 text-xs">
  ğŸ”¬ <strong class="text-cyan-400">Why it works:</strong> Retrieval failure is <em>silent</em>. Standard RAG doesn't know it found wrong documents â€” the LLM faithfully summarizes WRONG docs. The reranker score adds a <strong>signal</strong>: below threshold = the system <em>knows</em> it failed and can retry.
</div>
</v-click>

<!--
**Corrective RAG (5 mins)**

- Analogy: Quality inspector â†’ reject bad parts â†’ request replacements. The reranker IS the inspector.
- THE REAL INSIGHT: Retrieval failure is SILENT. Standard RAG has no idea it found the wrong documents. The LLM is a "faithful summarizer" â€” give it wrong context and it will confidently generate a wrong answer. There's no error message, no warning. The user gets a polished, confident, WRONG answer.
- CRAG adds a SIGNAL. The reranker score tells the system: "These documents scored 0.3 â€” they're probably not what you need." Now the system KNOWS it failed and can do something about it.
- The difference: Standard RAG = "confidently wrong." CRAG = "I'm not sure, let me try again."
- The Grader: We reuse the reranker (from Day 2) as a relevance scorer â€” 10Ã— faster than using an LLM as grader
- If best_score < 0.5 â†’ docs are probably wrong â†’ rewrite query and try again
- If best_score >= 0.5 â†’ docs are good enough â†’ generate answer
- Why reranker and not LLM? Speed. Reranker grades 5 documents in ~200ms. LLM would take 2-3 seconds. In a retry loop, this matters.

å»£æ±è©±ï¼š
- æ¯”å–»ï¼šå“è³ªæª¢æŸ¥å“¡ (QC) â†’ å½ˆè¿”è½‰é ­ â†’ è¦æ±‚æ›´æ›ã€‚Reranker å°±ä¿‚å€‹ QCã€‚
- çœŸæ­£å˜…æ´è¦‹ï¼šRetrieval å¤±æ•—ä¿‚éœæ‚„æ‚„å˜…ã€‚Standard RAG å””çŸ¥è‡ªå·±æµéŒ¯æ–‡ä»¶ã€‚LLM ä¿‚ã€Œå¿ å¯¦å˜…æ‘˜è¦å“¡ã€â€” ä¿¾éŒ¯å˜… context ä½¢ï¼Œä½¢æœƒè‡ªä¿¡å™‰ç”ŸæˆéŒ¯å˜…ç­”æ¡ˆã€‚å†‡éŒ¯èª¤è¨Šæ¯ï¼Œå†‡è­¦å‘Šã€‚ç”¨æˆ¶æ”¶åˆ°ä¸€å€‹ç²¾ç¾ã€è‡ªä¿¡ã€ä½†ä¿‚éŒ¯å˜…ç­”æ¡ˆã€‚
- CRAG åŠ å’—å€‹ä¿¡è™Ÿã€‚Reranker åˆ†æ•¸è©±ä¿¾ç³»çµ±çŸ¥ï¼šã€Œå‘¢å•²æ–‡ä»¶å¾— 0.3 åˆ† â€” å¯èƒ½å””ä¿‚ä½ è¦å˜…å˜¢ã€‚ã€è€Œå®¶ç³»çµ±çŸ¥é“è‡ªå·±å¤±æ•—å’—ï¼Œå¯ä»¥åšå•²å˜¢ã€‚
- åˆ†åˆ¥ï¼šStandard RAG = ã€Œè‡ªä¿¡å™‰éŒ¯ã€ã€‚CRAG = ã€Œæˆ‘å””è‚¯å®šï¼Œç­‰æˆ‘å†è©¦ä¸‹ã€‚ã€
- Graderï¼šæˆ‘å“‹é‡ç”¨ Reranker (Day 2) åšç›¸é—œæ€§è©•åˆ† â€” å¿«éç”¨ LLM åš grader 10 å€
- å¦‚æœ best_score < 0.5 â†’ æ–‡ä»¶å¯èƒ½éŒ¯ â†’ é‡å¯« query å†è©¦
- å¦‚æœ best_score >= 0.5 â†’ æ–‡ä»¶å¤ å¥½ â†’ ç”Ÿæˆç­”æ¡ˆ
- é»è§£ç”¨ reranker å””ç”¨ LLMï¼Ÿé€Ÿåº¦ã€‚Reranker è©• 5 ä»½æ–‡ä»¶å¤§ç´„ 200msã€‚LLM è¦ 2-3 ç§’ã€‚å–º retry loop å…¥é¢ï¼Œå‘¢å€‹å¥½é‡è¦ã€‚
-->

---
layout: center
---

# CRAG: Government Scenario

<div class="text-5xl mb-6">ğŸš¨</div>

<div class="text-lg mb-4"><span class="text-red-400">Scenario:</span> Critical Procedure Lookup</div>

<v-click>
<div class="p-4 border border-blue-500 rounded-lg bg-blue-900/20 mb-4">
  <div class="font-bold text-blue-400">User asks:</div>
  <div class="text-xl">"Procedure for Level 3 Alarm"</div>
</div>
</v-click>

<v-click>
<div class="p-4 border border-red-500 rounded-lg bg-red-900/20 mb-4">
  <div class="font-bold text-red-400">âŒ Standard RAG finds:</div>
  <div class="text-sm">"Level 2 Alarm Procedure" (similar but WRONG)</div>
  <div class="text-xs opacity-75 mt-1">Generates answer from wrong docs â†’ dangerous!</div>
</div>
</v-click>

<v-click>
<div class="p-4 border border-green-500 rounded-lg bg-green-900/20">
  <div class="font-bold text-green-400">âœ… CRAG detects the problem:</div>
  <div class="text-sm">Reranker scores Level 2 docs at 0.35 (below 0.5 threshold)</div>
  <div class="text-sm">â†’ Rewrites query â†’ Finds correct Level 3 docs â†’ Safe answer âœ…</div>
</div>
</v-click>

<!--
**CRAG Government Scenario (2 mins)**

- Critical procedure lookups: alarm levels, emergency protocols, use-of-force guidelines
- Getting the WRONG procedure is worse than no answer at all
- Standard RAG would happily generate from Level 2 docs when asked about Level 3
- CRAG catches this: reranker scores the docs, detects low relevance, rewrites and retries
- Best for: emergency procedures, compliance checklists, safety protocols
- Document types: structured procedures where precision is non-negotiable

å»£æ±è©±ï¼š
- é—œéµç¨‹åºæŸ¥è©¢ï¼šè­¦å ±ç´šåˆ¥ã€ç·Šæ€¥æŒ‡å¼•ã€æ­¦åŠ›ä½¿ç”¨æŒ‡å¼•
- æ”éŒ¯ç¨‹åº (Wrong procedure) æ¯”ç„¡ç­”æ¡ˆæ›´è¡°
- Standard RAG å• Level 3 ä½¢å¯èƒ½æœƒç…§ç”¨ Level 2 æ–‡ä»¶å»ç­”
- CRAG æœƒæ‰åˆ°ï¼šReranker ä¿¾åˆ†ä½ï¼Œç™¼ç¾ç›¸é—œæ€§å””å¤ ï¼Œé‡å¯«å†è©¦
- æœ€é©åˆï¼šç·Šæ€¥ç¨‹åºã€åˆè¦ Checklistã€å®‰å…¨æŒ‡å¼•
- æ–‡ä»¶é¡å‹ï¼šç²¾æº–åº¦ç„¡å¾—å¦¥å”å˜…çµæ§‹åŒ–ç¨‹åº
-->

---
layout: center
---

# Technique 5: Self-RAG

<div class="text-xl mb-4">Generate â†’ <span class="text-purple-400 font-bold">Reflect</span> â†’ Improve</div>

<div class="grid grid-cols-3 gap-6 text-center">
  <v-click>
  <div class="p-4 border border-blue-500 rounded-lg">
    <div class="text-4xl mb-2">ğŸ“</div>
    <div class="font-bold">1. Draft</div>
    <div class="text-xs opacity-75">Generate initial answer</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-4 border border-yellow-500 rounded-lg">
    <div class="text-4xl mb-2">ğŸª</div>
    <div class="font-bold text-yellow-400">2. Reflect</div>
    <div class="text-xs opacity-75">"Is this supported by context?"</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-4 border border-green-500 rounded-lg">
    <div class="text-4xl mb-2">ğŸ”¨</div>
    <div class="font-bold text-green-400">3. Refine</div>
    <div class="text-xs opacity-75">Retrieve more, regenerate</div>
  </div>
  </v-click>
</div>

<v-click>
<div class="mt-4 p-3 border border-purple-500 rounded-lg bg-purple-900/20 text-center text-sm">
  ğŸ’¡ <em>Like proofreading your own essay â€” draft it, re-read it, fix the gaps before submitting</em>
</div>
</v-click>

<v-click>
<div class="mt-2 p-3 border border-cyan-500 rounded-lg bg-cyan-900/20 text-xs">
  ğŸ”¬ <strong class="text-cyan-400">Why it works:</strong> Generation failure is <em>silent</em>. The LLM generates confidently even when hallucinating or only partially answering. Reflection catches two things: <strong>hallucination</strong> (info not in context) and <strong>incompleteness</strong> (only partial answer).
</div>
</v-click>

<!--
**Self-RAG (4 mins)**

- Analogy: Proofreading your own essay. Draft â†’ re-read â†’ fix gaps â†’ submit. The LLM is both writer and editor.
- THE REAL INSIGHT: Generation failure is SILENT â€” just like retrieval failure in CRAG. The LLM generates confidently even when it's hallucinating or only partially answering. There's no error, no warning. The user gets a polished, confident answer that might be wrong or incomplete.
- Reflection catches TWO failure modes:
  1. HALLUCINATION â€” the answer includes information that's NOT in the retrieved context. The LLM filled in gaps from its training data instead of saying "I don't know."
  2. INCOMPLETENESS â€” the answer only covers part of the question. The user asked about "minimum force AND reporting requirements" but the answer only covers minimum force.
- The LLM acts as both WRITER and EDITOR. First pass: generate. Second pass: "Does my answer actually follow from the context? Did I cover everything?"
- Cost: Slower (2-3 LLM calls per answer), but catches errors that would otherwise reach the user
- Key: The 8B model on GPU handles reflection well â€” fast enough to iterate
- vs CRAG: CRAG catches bad RETRIEVAL (wrong documents). Self-RAG catches bad GENERATION (wrong answer from right documents). They fix different failure points.

å»£æ±è©±ï¼š
- æ¯”å–»ï¼šè‡ªå·±æ ¡å°ç¯‡æ–‡ã€‚å¯«åˆç¨¿ â†’ é‡è®€ â†’ è£œçª¿ â†’ äº¤å·ã€‚LLM æ—¢ä¿‚ä½œè€…åˆä¿‚ç·¨è¼¯ã€‚
- çœŸæ­£å˜…æ´è¦‹ï¼šGeneration å¤±æ•—éƒ½ä¿‚éœæ‚„æ‚„å˜… â€” åŒ CRAG å…¥é¢å˜… retrieval å¤±æ•—ä¸€æ¨£ã€‚LLM å³ä½¿å¹»è¦ºæˆ–è€…åªä¿‚éƒ¨åˆ†å›ç­”ï¼Œéƒ½æœƒè‡ªä¿¡å™‰ç”Ÿæˆã€‚å†‡éŒ¯èª¤ï¼Œå†‡è­¦å‘Šã€‚ç”¨æˆ¶æ”¶åˆ°ä¸€å€‹ç²¾ç¾ã€è‡ªä¿¡å˜…ç­”æ¡ˆï¼Œä½†å¯èƒ½ä¿‚éŒ¯æˆ–è€…å””å®Œæ•´ã€‚
- Reflection æ‰åˆ°å…©ç¨®å¤±æ•—æ¨¡å¼ï¼š
  1. å¹»è¦º â€” ç­”æ¡ˆåŒ…å«å””å–º context å…¥é¢å˜…è³‡è¨Šã€‚LLM ç”¨è¨“ç·´æ•¸æ“šå¡«è£œç©ºç™½ï¼Œè€Œå””ä¿‚è¬›ã€Œæˆ‘å””çŸ¥ã€ã€‚
  2. ä¸å®Œæ•´ â€” ç­”æ¡ˆåªæ¶µè“‹éƒ¨åˆ†å•é¡Œã€‚ç”¨æˆ¶å•ã€Œæœ€ä½æ­¦åŠ›åŒå ±å‘Šè¦æ±‚ã€ä½†ç­”æ¡ˆåªè¬›æœ€ä½æ­¦åŠ›ã€‚
- LLM åŒæ™‚åšä½œè€…åŒç·¨è¼¯ã€‚ç¬¬ä¸€è¼ªï¼šç”Ÿæˆã€‚ç¬¬äºŒè¼ªï¼šã€Œæˆ‘å˜…ç­”æ¡ˆä¿‚å’ªçœŸä¿‚ç”± context æ”¯æŒï¼Ÿæˆ‘æœ‰å†‡æ¶µè“‹æ™’æ‰€æœ‰å˜¢ï¼Ÿã€
- ä»£åƒ¹ï¼šæ…¢å•² (æ¯æ¢ç­”æ¡ˆ 2-3 å€‹ LLM calls)ï¼Œä½†æ‰åˆ°æœ¬ä¾†æœƒåˆ°é”ç”¨æˆ¶å˜…éŒ¯èª¤
- é—œéµï¼šGPU ä¸Šå˜… 8B model åš reflection åšå¾—å¥½å¥½ â€” å¤ å¿«å¯ä»¥ iterate
- åŒ CRAG æ¯”è¼ƒï¼šCRAG æ‰å£å˜… RETRIEVALï¼ˆéŒ¯å˜…æ–‡ä»¶ï¼‰ã€‚Self-RAG æ‰å£å˜… GENERATIONï¼ˆç”±å•±å˜…æ–‡ä»¶ç”ŸæˆéŒ¯å˜…ç­”æ¡ˆï¼‰ã€‚ä½¢å“‹ä¿®å¾©å””åŒå˜…å¤±æ•—é»ã€‚
-->

---
layout: center
---

# Self-RAG: Government Scenario

<div class="text-5xl mb-6">ğŸ“‹</div>

<div class="text-lg mb-4"><span class="text-purple-400">Scenario:</span> Drafting Official Replies</div>

<v-click>
<div class="p-4 border border-blue-500 rounded-lg bg-blue-900/20 mb-4">
  <div class="font-bold text-blue-400">Task:</div>
  <div class="text-sm">"Compare the old and new procurement guidelines"</div>
</div>
</v-click>

<v-click>
<div class="p-4 border border-yellow-500 rounded-lg bg-yellow-900/20 mb-4">
  <div class="font-bold text-yellow-400">ğŸª Reflection catches:</div>
  <div class="text-sm">"Answer only covers new guidelines. Missing comparison with old version."</div>
  <div class="text-xs opacity-75 mt-1">â†’ NEEDS_IMPROVEMENT</div>
</div>
</v-click>

<v-click>
<div class="p-4 border border-green-500 rounded-lg bg-green-900/20">
  <div class="font-bold text-green-400">âœ… After refinement:</div>
  <div class="text-sm">Retrieves old guidelines too â†’ comprehensive comparison â†’ accurate reply</div>
</div>
</v-click>

<!--
**Self-RAG Government Scenario (2 mins)**

- Complex policy analysis: comparing old vs new regulations, summarizing multi-part guidelines
- First draft often misses nuances or only covers part of the question
- Reflection catches gaps: "Missing comparison", "Only covers Section A, not B"
- System retrieves more context and regenerates a complete answer
- Best for: official replies, press releases, legal summaries, audit reports
- Document types: complex multi-section documents where completeness matters

å»£æ±è©±ï¼š
- è¤‡é›œæ”¿ç­–åˆ†æï¼šæ¯”è¼ƒæ–°èˆŠè¦ä¾‹ã€ç¸½çµå¤šéƒ¨åˆ†å˜…æŒ‡å¼•
- ç¬¬ä¸€ç¨¿é€šå¸¸æœƒæ¼å’—å•²ç´°ç¯€æˆ–è€…åªç­”å’—ä¸€éƒ¨åˆ†
- Reflection æœƒæ‰åˆ°æ¼æ´ï¼š"Missing comparison"ã€"Only covers Section A, not B"
- ç³»çµ±æœƒ retrieve æ›´å¤š context å†ç”Ÿæˆå®Œæ•´ç­”æ¡ˆ
- æœ€é©åˆï¼šå®˜æ–¹å›è¦†ã€æ–°èç¨¿ã€æ³•å¾‹æ‘˜è¦ã€å¯©è¨ˆå ±å‘Š
- æ–‡ä»¶é¡å‹ï¼šå®Œæ•´æ€§å¥½é‡è¦å˜…è¤‡é›œå¤šç« ç¯€æ–‡ä»¶
-->

---
layout: center
---

# Technique Summary

<div class="text-sm">

| Technique | Fixes | Best For | Cost |
|---|---|---|---|
| **Multi-Query** | Bad queries (ambiguity) | Citizen inquiries, FAQ bots | 1 LLM call + 4 searches |
| **HyDE** | Semantic gap (shortâ†’long) | Policy docs, General Orders | 1 LLM call + 1 embed |
| **Modular RAG** | Wrong strategy | Multi-user portals | 1 classifier call |
| **CRAG** | Bad retrieval | Emergency procedures | 1 reranker + retry loop |
| **Self-RAG** | Bad answers | Official replies, audits | 2-3 LLM calls |

</div>

<v-click>
<div class="mt-6 p-3 border border-yellow-500 rounded-lg bg-yellow-900/20 text-center text-sm">
  ğŸ’¡ No "best" technique â€” pick the one that matches your failure mode
</div>
</v-click>

<!--
**Technique Summary (2 mins)**

- Quick reference table â€” each technique addresses a specific failure mode
- Multi-Query and HyDE fix the INPUT (query enhancement)
- Modular RAG fixes the STRATEGY (routing)
- CRAG fixes the RETRIEVAL (quality gate)
- Self-RAG fixes the OUTPUT (answer quality)
- Key takeaway: Match the technique to your problem, not the other way around

å»£æ±è©±ï¼š
- å¿«é€Ÿåƒè€ƒè¡¨ â€” æ¯ç¨®æŠ€è¡“é‡å°ä¸€ç¨®ç‰¹å®šå¤±æ•—æ¨¡å¼
- Multi-Query åŒ HyDE æ INPUT (Query å¢å¼·)
- Modular RAG æ STRATEGY (è·¯ç”±)
- CRAG æ RETRIEVAL (Quality gate)
- Self-RAG æ OUTPUT (ç­”æ¡ˆè³ªç´ )
- é‡é»ï¼šç‡ä½ å€‹å•é¡Œä¿‚å’©ï¼Œå…ˆæ€ç”¨å’©æŠ€è¡“ï¼Œå””å¥½æ‰è½‰
-->

---
layout: center
---

# ğŸ”§ Setup: Your Code Becomes a Library

<div class="grid grid-cols-2 gap-6 text-sm">
  <div>
    <div class="font-bold text-green-400 mb-3">Step 1: Make Part 3 importable</div>

```bash
cp workshop/docling-part3-exercise.py \
   workshop/docling_part3.py
```

  <v-click>
    <div class="font-bold text-green-400 mb-3 mt-4">Step 2: Import YOUR functions</div>

```python
from docling_part3 import (
    _connect_db,
    _search_vector, _search_bm25,
    _hybrid_search, _generate_answer,
    _add_embeddings, _create_indexes,
    EMBED_MODEL, RRF_K,
)
```

  </v-click>
  </div>

  <v-click>
  <div>
    <div class="font-bold text-purple-400 mb-3">Step 3: Add remote models</div>

```python
from openai import OpenAI

chat_client = OpenAI(
    base_url="https://...modal.run/v1",
    api_key="not-needed",
)
CHAT_MODEL = "qwen3-vl-8b"
```

  <div class="mt-4 p-3 border border-blue-500 rounded-lg bg-blue-900/20 text-xs">
    <div class="font-bold text-blue-400 mb-1">ğŸ’¡ What just happened?</div>
    Every function you wrote in Parts 1-3 is now callable.<br/>
    Your tweaks, your prompts, your parameters â€” all preserved.
  </div>
  </div>
  </v-click>
</div>

<!--
**Setup: Your Code Becomes a Library (3 mins)**

- Step 1: One `cp` command makes your Part 3 file importable as a Python module
- Step 2: Import all the functions you built â€” search, embeddings, generation
- Step 3: Add the remote GPU models (chat_client + _rerank) â€” provided in the exercise file
- Key message: You're NOT starting from scratch. Your Part 3 code IS the foundation.
- Any customizations students made (prompt changes, parameter tweaks) carry over automatically

å»£æ±è©±ï¼š
- Step 1ï¼šä¸€å€‹ `cp` command å°±å¯ä»¥å°‡ä½  Part 3 å˜… file è®Šæˆ Python module
- Step 2ï¼šImport ä½ å¯«éå˜…æ‰€æœ‰ function â€” searchã€embeddingsã€generation
- Step 3ï¼šåŠ  remote GPU models (chat_client + _rerank) â€” exercise file å…¥é¢å·²ç¶“æœ‰
- é‡é»ï¼šä½ å””ä¿‚ç”±é›¶é–‹å§‹ã€‚ä½  Part 3 å˜… code å°±ä¿‚å€‹åŸºç¤ã€‚
- ä½ ä¹‹å‰æ”¹éå˜…å˜¢ï¼ˆpromptã€åƒæ•¸ï¼‰å…¨éƒ¨è‡ªå‹•ä¿ç•™
-->

---
layout: center
---

# â™»ï¸ What You Reuse vs What You Write

<div class="text-sm mb-4">

| Path | Your Part 1-3 Functions | New Lines |
|---|---|---|
| ğŸŸ¢ **A** Robust | `_search_vector` Â· `_hybrid_search` Â· `ollama.embed` Â· `RRF_K` | **~60** |
| ğŸŸ¡ **B** Modular | `_search_bm25` Â· `_search_vector` Â· `_hybrid_search` Â· `ollama.embed` | **~80** |
| ğŸ”´ **C** CRAG | `_hybrid_search` Â· `_generate_answer` Â· `_rerank` | **~55** |
| ğŸŸ£ **D** Self-RAG | `_hybrid_search` Â· `_generate_answer` | **~50** |

</div>

<v-click>
<div class="grid grid-cols-2 gap-6 mt-4">
  <div class="p-4 border border-green-500 rounded-lg bg-green-900/20 text-center">
    <div class="text-4xl font-bold text-green-400">200+</div>
    <div class="text-sm opacity-75">lines you REUSE from Parts 1-3</div>
  </div>
  <div class="p-4 border border-yellow-500 rounded-lg bg-yellow-900/20 text-center">
    <div class="text-4xl font-bold text-yellow-400">50-80</div>
    <div class="text-sm opacity-75">new lines you WRITE today</div>
  </div>
</div>
</v-click>

<v-click>
<div class="mt-4 text-center text-sm opacity-75">
  You already built the engine. Today you learn to <span class="text-green-400 font-bold">drive</span>.
</div>
</v-click>

<!--
**What You Reuse vs What You Write (2 mins)**

- Show the table â€” every path reuses multiple Part 1-3 functions
- The big numbers: 200+ lines reused vs 50-80 new lines
- Path A and B reuse the most search functions (they enhance search)
- Path C and D reuse _generate_answer (they enhance generation quality)
- Key message: You're not building from scratch â€” you're adding a thin layer of intelligence on top of a solid foundation
- "You already built the engine. Today you learn to drive."

å»£æ±è©±ï¼š
- ç‡å€‹è¡¨ â€” æ¯æ¢è·¯éƒ½é‡ç”¨å¥½å¤š Part 1-3 å˜… function
- å¤§æ•¸å­—ï¼šé‡ç”¨ 200+ è¡Œ vs æ–°å¯« 50-80 è¡Œ
- Path A åŒ B é‡ç”¨æœ€å¤š search functionï¼ˆä½¢å“‹ä¿‚å¢å¼·æœå°‹ï¼‰
- Path C åŒ D é‡ç”¨ `_generate_answer`ï¼ˆä½¢å“‹ä¿‚å¢å¼·ç”Ÿæˆè³ªç´ ï¼‰
- é‡é»ï¼šä½ å””ä¿‚ç”±é›¶é–‹å§‹ â€” ä½ ä¿‚å–ºä¸€å€‹ç©©å›ºå˜…åŸºç¤ä¸Šé¢åŠ ä¸€å±¤è–„è–„å˜…æ™ºèƒ½
- ã€Œä½ å·²ç¶“ç Œå¥½å€‹å¼•æ“ã€‚ä»Šæ—¥å­¸æ¸è»Šã€‚ã€
-->

---
layout: section
---

# â˜• Hands-On: Choose Your Path

<div class="text-xl opacity-75">Build One Advanced RAG Pipeline</div>

<div class="text-sm opacity-50 mt-4">100 minutes Â· All paths are self-contained</div>

---
layout: center
---

# ğŸ—ºï¸ Choose Your Adventure

<div class="grid grid-cols-2 gap-6 text-sm">
  <v-click>
  <div class="p-4 border-2 border-green-500 rounded-xl">
    <div class="text-xl font-bold text-green-400">ğŸŸ¢ Path A: Robust RAG</div>
    <div class="text-xs uppercase tracking-wide opacity-75 mb-2">Recommended Â· ~60 lines</div>
    <div class="space-y-1 text-xs">
      <div>âœ… Build HyDE + Multi-Query</div>
      <div>âœ… Strategy toggle wrapper</div>
      <div>âœ… Optional reranking</div>
    </div>
    <div class="mt-3 text-xs italic opacity-75">"I want a solid, production-grade search."</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-4 border-2 border-yellow-500 rounded-xl">
    <div class="text-xl font-bold text-yellow-400">ğŸŸ¡ Path B: Modular RAG</div>
    <div class="text-xs uppercase tracking-wide opacity-75 mb-2">The Architect Â· ~80 lines</div>
    <div class="space-y-1 text-xs">
      <div>âœ… Build HyDE + Multi-Query</div>
      <div>âœ… Query classifier</div>
      <div>âœ… Dynamic routing</div>
    </div>
    <div class="mt-3 text-xs italic opacity-75">"I want to optimize for different user types."</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-4 border-2 border-red-500 rounded-xl">
    <div class="text-xl font-bold text-red-400">ğŸ”´ Path C: Corrective RAG</div>
    <div class="text-xs uppercase tracking-wide opacity-75 mb-2">High Reliability Â· ~55 lines</div>
    <div class="space-y-1 text-xs">
      <div>âœ… Reranker as grader</div>
      <div>âœ… Query rewriting</div>
      <div>âœ… Retry loops</div>
    </div>
    <div class="mt-3 text-xs italic opacity-75">"I want the system to fix itself."</div>
  </div>
  </v-click>
  <v-click>
  <div class="p-4 border-2 border-purple-500 rounded-xl">
    <div class="text-xl font-bold text-purple-400">ğŸŸ£ Path D: Self-RAG</div>
    <div class="text-xs uppercase tracking-wide opacity-75 mb-2">The Perfectionist Â· ~50 lines</div>
    <div class="space-y-1 text-xs">
      <div>âœ… Generation loop</div>
      <div>âœ… Self-reflection</div>
      <div>âœ… Iterative refinement</div>
    </div>
    <div class="mt-3 text-xs italic opacity-75">"I want the highest quality answer."</div>
  </div>
  </v-click>
</div>

<!--
**Choose Your Path (3 mins)**

- You have 100 minutes. Pick ONE path.
- All paths use your Part 3 code as the foundation
- Path A is the "Swiss Army Knife" â€” great for general understanding, not a fallback
- Path B is for architects who want to design intelligent systems
- Path C is the most creative use of reranking â€” reranker becomes the grader
- Path D is for perfectionists who want the highest quality answers
- Every path is self-contained with all the code you need

å»£æ±è©±ï¼š
- ä½ æœ‰ 100 åˆ†é˜ã€‚æ€ **ä¸€æ¢** è·¯ã€‚
- æ‰€æœ‰è·¯éƒ½ä¿‚åŸºæ–¼ä½  Part 3 å˜… code
- Path A ä¿‚ã€Œè¬èƒ½åˆ€ã€â€” å°æ•´é«”ç†è§£æœ€å¥½ï¼Œå””ä¿‚å¾Œå‚™é¸é …
- Path B ä¿‚ä¿¾æƒ³è¨­è¨ˆæ™ºèƒ½ç³»çµ±å˜…æ¶æ§‹å¸«
- Path C ä¿‚æœ€æœ‰å‰µæ„å’ç”¨ Reranker â€” Reranker è®Šå’—åš Grader
- Path D ä¿‚ä¿¾æƒ³è¦æœ€é«˜è³ªç´ ç­”æ¡ˆå˜…å®Œç¾ä¸»ç¾©è€…
- æ¯æ¢è·¯éƒ½ä¿‚ Self-containedï¼Œæœ‰é½Šä½ éœ€è¦å˜… code
-->

---
layout: center
---

# ğŸŸ¢ Path A: Robust RAG

<div class="text-sm mb-2"><span class="text-green-400 font-bold">Robust RAG</span> = your basic RAG pipeline hardened with <strong>multiple search strategies</strong> so it doesn't break on bad queries</div>
<div class="text-xs mb-4 opacity-75">Combine HyDE + Multi-Query + Reranking behind a single strategy flag â†’ one function handles any query type</div>

<Transform :scale="1.2" origin="center">

```mermaid
flowchart LR
    Q[ğŸ” Query] --> STRAT{"Strategy Flag"}
    STRAT -->|hyde| HYDE[hyde_search]
    STRAT -->|multi| MQ[multi_query_search]
    STRAT -->|hybrid| HYB[_hybrid_search]
    HYDE --> RR[âš–ï¸ _rerank\noptional]
    MQ --> RR
    HYB --> RR
    RR --> GEN[ğŸ¤– Generate]

    style Q fill:#3b82f6,color:#fff
    style STRAT fill:#eab308,color:#000
    style HYDE fill:#22c55e,color:#000
    style MQ fill:#22c55e,color:#000
    style HYB fill:#22c55e,color:#000
    style RR fill:#a855f7,color:#fff
    style GEN fill:#a855f7,color:#fff
```

</Transform>

<v-click>
<div class="mt-8 grid grid-cols-4 gap-3 text-xs text-center">
  <div class="p-2 border border-green-500 rounded">Step 1: hyde_search()</div>
  <div class="p-2 border border-green-500 rounded">Step 2: multi_query_search()</div>
  <div class="p-2 border border-green-500 rounded">Step 3: robust_search() wrapper</div>
  <div class="p-2 border border-yellow-500 rounded">Step 4: Experiment</div>
</div>
</v-click>

<!--
**Path A Overview (2 mins)**

- WHAT IS ROBUST RAG? It's not a named technique from a paper â€” it's a practical pattern. You take your basic RAG pipeline and make it ROBUST by giving it multiple search strategies (HyDE, Multi-Query, Hybrid) behind a single function. Instead of one search path that breaks on certain queries, you have a toolkit of strategies + optional reranking. The user (or a flag) picks the best one.
- WHY "ROBUST"? Because no single search strategy works for all queries. HyDE is great for vague conceptual queries but overkill for exact lookups. Multi-Query is great for ambiguous queries but adds latency. Hybrid is fast but misses semantic gaps. Robust RAG = having all three + the ability to switch.
- Build two query enhancement techniques, then wrap them in a production-quality function
- Step 1: hyde_search() â€” generate fake answer, embed it, search (~15 lines)
- Step 2: multi_query_search() â€” generate 3 variants, search all, RRF merge (~25 lines)
- Step 3: robust_search() â€” strategy selection + optional reranking + timing (~20 lines)
- Step 4: Experiment â€” compare strategies, add CLI flags, handle edge cases
- Total: ~60 new lines on top of your Part 3 code

å»£æ±è©±ï¼š
- å’©ä¿‚ Robust RAGï¼Ÿå””ä¿‚ä¸€ç¯‡ paper å˜…å â€” ä¿‚ä¸€å€‹å¯¦ç”¨ patternã€‚ä½ æ”ä½ å˜…åŸºæœ¬ RAG pipelineï¼ŒåŠ å…¥å¤šç¨®æœå°‹ç­–ç•¥ (HyDEã€Multi-Queryã€Hybrid) åŒ…è£å–ºä¸€å€‹ function å…¥é¢ã€‚å””å†å¾—ä¸€æ¢æœå°‹è·¯å¾‘æœƒå–ºæŸå•² query ä¸Šé¢æ­»ï¼Œè€Œä¿‚æœ‰ä¸€å€‹ç­–ç•¥å·¥å…·ç®± + optional rerankingã€‚ç”¨æˆ¶ï¼ˆæˆ–è€…ä¸€å€‹ flagï¼‰æ€æœ€å¥½å˜…ã€‚
- é»è§£å«ã€ŒRobustã€ï¼Ÿå› ç‚ºå†‡ä¸€ç¨®æœå°‹ç­–ç•¥é©åˆæ‰€æœ‰ queryã€‚HyDE å°å«ç³Šæ¦‚å¿µæ€§ query å¥½å¥½ä½†å°ç²¾ç¢ºæŸ¥è©¢å¤ªå¤§é™£ä»—ã€‚Multi-Query å°æ¨¡ç³Š query å¥½å¥½ä½†åŠ å’—å»¶é²ã€‚Hybrid å¿«ä½† miss èªç¾©é´»æºã€‚Robust RAG = ä¸‰ç¨®éƒ½æœ‰ + å¯ä»¥åˆ‡æ›ã€‚
- èµ·å…©å€‹ query å¢å¼·æŠ€è¡“ï¼Œç„¶å¾ŒåŒ…è£æˆä¸€å€‹ Production-quality å˜… function
- Step 1: `hyde_search()` â€” ç”Ÿæˆå‡ç­”æ¡ˆï¼Œembedï¼Œsearch (~15 è¡Œ)
- Step 2: `multi_query_search()` â€” ç”Ÿæˆ 3 å€‹è®Šé«”ï¼Œsearch æ™’ï¼ŒRRF merge (~25 è¡Œ)
- Step 3: `robust_search()` â€” ç­–ç•¥é¸æ“‡ + Optional reranking + è¨ˆæ™‚ (~20 è¡Œ)
- Step 4: å¯¦é©— â€” æ¯”è¼ƒå””åŒç­–ç•¥ï¼ŒåŠ  CLI flagsï¼Œè™•ç†é‚Šç·£æƒ…æ³
- ç¸½å…±ï¼šå–ºä½  Part 3 code ä¹‹ä¸ŠåŠ ç´„ 60 è¡Œ
-->

---
layout: center
---

# Path A: Key Code â€” HyDE Search

```python {all|2-5|7-8|10}
def hyde_search(conn, query, top_k=5):
    resp = chat_client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[{"role": "user",
                   "content": f"Write a short passage that answers: {query}"}],
    )
    fake_answer = resp.choices[0].message.content
    hyde_vec = ollama.embed(model=EMBED_MODEL, input=fake_answer)["embeddings"][0]

    return _search_vector(conn, hyde_vec, limit=top_k)
```

<v-click>
<div class="mt-6 grid grid-cols-3 gap-4 text-xs">
  <div class="p-3 bg-purple-900/30 rounded border border-purple-500">
    <div class="opacity-75">Step 1:</div>
    <div>ğŸ¤– Remote LLM generates fake answer</div>
  </div>
  <div class="p-3 bg-yellow-900/30 rounded border border-yellow-500">
    <div class="opacity-75">Step 2:</div>
    <div>ğŸ§  Local embed the fake answer</div>
  </div>
  <div class="p-3 bg-green-900/30 rounded border border-green-500">
    <div class="opacity-75">Step 3:</div>
    <div>ğŸ” Vector search with that embedding</div>
  </div>
</div>
</v-click>

<!--
**Path A: HyDE Code (2 mins)**

- Line 2-5: Call remote LLM to generate a fake answer (GPU â€” fast!)
- Line 7: Extract the fake answer text
- Line 8: Embed the fake answer LOCALLY (not the query!)
- Line 10: Search using the fake answer's embedding â€” reuses _search_vector from Part 3
- Key insight: The fake answer doesn't need to be correct, just semantically similar

å»£æ±è©±ï¼š
- Line 2-5ï¼šCall remote LLM ç”Ÿæˆå‡ç­”æ¡ˆ (GPU â€” å¿«ï¼)
- Line 7ï¼šæå–å‡ç­”æ¡ˆæ–‡å­—
- Line 8ï¼šå–º **LOCAL** embed å€‹å‡ç­”æ¡ˆ (å””ä¿‚å€‹ queryï¼)
- Line 10ï¼šç”¨å‡ç­”æ¡ˆå˜… embedding åš search â€” é‡ç”¨ Part 3 å˜… `_search_vector`
- é—œéµï¼šå‡ç­”æ¡ˆå””éœ€è¦æ­£ç¢ºï¼Œåªéœ€è¦èªç¾©ç›¸ä¼¼
-->

---
layout: center
---

# Path A: Key Code â€” Multi-Query Search

```python {all|2-6|8-9|11-16|18-20}
def multi_query_search(conn, query, top_k=5):
    resp = chat_client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[{"role": "user", "content": (
            f"Generate 3 different search queries for: {query}\n"
            "Return one query per line. No numbering.")}],
    )
    variants = resp.choices[0].message.content.strip().split("\n")[:3]
    all_queries = [query] + variants  # original + 3 variants

    fused_scores, chunk_texts = {}, {}
    for q in all_queries:
        results = _hybrid_search(conn, q, top_k=top_k)
        for rank, r in enumerate(results):
            cid = r["chunk_id"]
            fused_scores[cid] = fused_scores.get(cid, 0) + 1.0 / (RRF_K + rank + 1)
            chunk_texts[cid] = r["text"]

    sorted_results = sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)[:top_k]
    return [{"chunk_id": cid, "text": chunk_texts[cid], "rrf_score": score}
            for cid, score in sorted_results]
```

<v-click>
<div class="mt-4 p-3 border border-green-500 rounded-lg bg-green-900/20 text-center text-sm">
  â™»ï¸ Reuses <code>_hybrid_search()</code> and <code>RRF_K</code> from Part 3 â€” same fusion algorithm!
</div>
</v-click>

<!--
**Path A: Multi-Query Code (2 mins)**

- Line 2-6: Ask remote LLM to generate 3 query variants
- Line 8-9: Parse variants, combine with original query (4 total)
- Line 11-16: Search with each query, fuse scores using RRF (same algorithm from Part 3!)
- Line 18-20: Sort by fused score, return top results
- Key: This is RRF-on-RRF â€” each _hybrid_search already uses RRF internally

å»£æ±è©±ï¼š
- Line 2-6ï¼šå« Remote LLM ç”Ÿæˆ 3 å€‹ query è®Šé«”
- Line 8-9ï¼šParse è®Šé«”ï¼ŒåŠ åŸ‹åŸè£ query (ç¸½å…± 4 å€‹)
- Line 11-16ï¼šæ¯å€‹ query åš searchï¼Œç”¨ RRF èåˆåˆ†æ•¸ (åŒ Part 3 ç®—æ³•ä¸€æ¨£ï¼)
- Line 18-20ï¼šæŒ‰èåˆåˆ†æ•¸æ’å¥½ï¼Œreturn top results
- é—œéµï¼šå‘¢å€‹ä¿‚ RRF-on-RRF â€” æ¯å€‹ `_hybrid_search` è£¡é¢å·²ç¶“ç”¨ç·Š RRF
-->

---
layout: center
---

# Path A: Key Code â€” Production Wrapper

```python {all|1|4-9|11-14|16-17}
def robust_search(conn, query, strategy="hyde", use_rerank=True, top_k=5):
    import time; start = time.time()

    if strategy == "hyde":
        candidates = hyde_search(conn, query, top_k=top_k * 2)
    elif strategy == "multi":
        candidates = multi_query_search(conn, query, top_k=top_k * 2)
    else:
        candidates = _hybrid_search(conn, query, top_k=top_k * 2)

    if use_rerank:
        texts = [c["text"] for c in candidates]
        reranked = _rerank(query, texts, top_k=top_k)
        results = [{"text": t, "score": s} for t, s in reranked]
    else:
        results = candidates[:top_k]

    print(f"â±ï¸ {strategy}{' + rerank' if use_rerank else ''}: "
          f"{time.time()-start:.1f}s | {len(results)} results")
    return results
```

<v-click>
<div class="mt-4 grid grid-cols-3 gap-3 text-xs text-center">
  <div class="p-2 bg-green-900/30 rounded border border-green-500">
    <div class="font-mono">--strategy hyde</div>
    <div class="opacity-75">Semantic bridge</div>
  </div>
  <div class="p-2 bg-blue-900/30 rounded border border-blue-500">
    <div class="font-mono">--strategy multi</div>
    <div class="opacity-75">Vocabulary expansion</div>
  </div>
  <div class="p-2 bg-yellow-900/30 rounded border border-yellow-500">
    <div class="font-mono">--rerank</div>
    <div class="opacity-75">Optional quality boost</div>
  </div>
</div>
</v-click>

<!--
**Path A: Wrapper Code (2 mins)**

- Line 1: Single function with strategy flag + rerank toggle
- Line 4-9: Strategy selection â€” pick the right search based on flag
- Line 11-14: Optional reranking â€” _rerank() from setup code
- Line 16-17: Fallback â€” just truncate if no reranking
- This is the "production" pattern: configurable, measurable, extensible

å»£æ±è©±ï¼š
- Line 1ï¼šå–®ä¸€ function åŒ…æ™’ç­–ç•¥ flag + rerank toggle
- Line 4-9ï¼šç­–ç•¥é¸æ“‡ â€” æ ¹æ“š flag æ€å•±å˜… search
- Line 11-14ï¼šOptional reranking â€” ç”¨ setup code å˜… `_rerank()`
- Line 16-17ï¼šFallback â€” å¦‚æœå”” rerank å°±ç›´æ¥ truncate
- å‘¢å€‹ä¿‚ "Production" patternï¼šå¯é…ç½®ã€å¯é‡åº¦ã€å¯æ“´å±•
-->

---
layout: center
---

# ğŸŸ¡ Path B: Modular RAG

<div class="text-sm mb-4">Build HyDE + Multi-Query + Intelligent Router</div>

<Transform :scale="1.0" origin="center">

```mermaid
flowchart TB
    Q[ğŸ” Query] --> CLS[ğŸ¤– classify_query]
    CLS -->|factual| BM25[ğŸ“ _search_bm25]
    CLS -->|conceptual| HYDE[ğŸ§  hyde_search]
    CLS -->|ambiguous| MQ[ğŸ”€ multi_query_search]
    BM25 --> GEN[ğŸ¤– Generate]
    HYDE --> GEN
    MQ --> GEN

    style Q fill:#3b82f6,color:#fff
    style CLS fill:#eab308,color:#000
    style BM25 fill:#22c55e,color:#000
    style HYDE fill:#22c55e,color:#000
    style MQ fill:#22c55e,color:#000
    style GEN fill:#a855f7,color:#fff
```

</Transform>

<v-click>
<div class="mt-4 grid grid-cols-4 gap-3 text-xs text-center">
  <div class="p-2 border border-green-500 rounded">Step 1: hyde_search()</div>
  <div class="p-2 border border-green-500 rounded">Step 2: multi_query_search()</div>
  <div class="p-2 border border-yellow-500 rounded">Step 3: classify + route</div>
  <div class="p-2 border border-purple-500 rounded">Bonus: Metadata routing</div>
</div>
</v-click>

<!--
**Path B Overview (2 mins)**

- HOW IS THIS DIFFERENT FROM PATH A (ROBUST RAG)?
  - Path A (Robust RAG): The USER picks the strategy manually via a CLI flag (`--strategy hyde`). It's a toolkit â€” you choose which tool to use.
  - Path B (Modular RAG): The LLM picks the strategy automatically. A classifier reads the query, decides if it's factual/conceptual/ambiguous, and routes to the best strategy. No human decision needed.
  - Think of it this way: Path A = manual gearbox, Path B = automatic transmission. Same engine underneath, different driver experience.
  - Path A is a stepping stone TO Path B â€” you build the same search functions (HyDE, Multi-Query), then Path B adds a brain (the router) on top.

- FAQ: "Can I use multiple strategies at the same time, like --strategy hyde multi?"
  - No â€” both Path A and Path B run ONE strategy per query. The pipeline does NOT aggregate results from multiple strategies.
  - Why? Each strategy already does heavy work (LLM calls, multiple searches, RRF fusion). Running two would double latency for marginal gain.
  - If you WANT multi-strategy aggregation, that's essentially what Multi-Query already does â€” it runs 4 searches and fuses them with RRF. You'd be doing RRF-on-RRF-on-RRF, which has diminishing returns.
  - The better approach is what Modular RAG does: pick the RIGHT strategy for each query, not throw everything at every query.

- Steps 1-2: Same as Path A â€” build HyDE and Multi-Query first
- Step 3: The NEW part â€” build a classifier that routes queries to the best strategy
- Bonus: Use Docling metadata (section_title) for pre-filtering
- Total: ~80 new lines on top of Part 3 code

å»£æ±è©±ï¼š
- åŒ PATH A (ROBUST RAG) æœ‰å’©åˆ†åˆ¥ï¼Ÿ
  - Path A (Robust RAG)ï¼šç”¨æˆ¶è‡ªå·±æ€ç­–ç•¥ï¼Œç”¨ CLI flag (`--strategy hyde`)ã€‚ä¿‚ä¸€å€‹å·¥å…·ç®± â€” ä½ æ€ç”¨é‚Šå€‹å·¥å…·ã€‚
  - Path B (Modular RAG)ï¼šLLM è‡ªå‹•æ€ç­–ç•¥ã€‚Classifier è®€å€‹ queryï¼Œåˆ¤æ–·ä¿‚ factual/conceptual/ambiguousï¼Œè‡ªå‹•è·¯ç”±å»æœ€ä½³ç­–ç•¥ã€‚å””éœ€è¦äººåšæ±ºå®šã€‚
  - å’è«—ï¼šPath A = æ£æ³¢ï¼ŒPath B = è‡ªå‹•æ³¢ã€‚åº•ä¸‹åŒä¸€å€‹å¼•æ“ï¼Œä½†é§•é§›é«”é©—å””åŒã€‚
  - Path A ä¿‚ Path B å˜…è¸è…³çŸ³ â€” ä½ èµ·åŒæ¨£å˜… search functions (HyDEã€Multi-Query)ï¼Œç„¶å¾Œ Path B åŠ å€‹è…¦ (router) å–ºä¸Šé¢ã€‚

- å¸¸è¦‹å•é¡Œï¼šã€Œå¯å””å¯ä»¥åŒæ™‚ç”¨å¹¾å€‹ç­–ç•¥ï¼Œå¥½ä¼¼ --strategy hyde multiï¼Ÿã€
  - å””å¾— â€” Path A åŒ Path B æ¯å€‹ query éƒ½åªè¡Œä¸€å€‹ç­–ç•¥ã€‚Pipeline å””æœƒèšåˆå¤šå€‹ç­–ç•¥å˜…çµæœã€‚
  - é»è§£ï¼Ÿæ¯å€‹ç­–ç•¥å·²ç¶“åšå¥½å¤šå˜¢ (LLM callsã€å¤šæ¬¡ searchã€RRF fusion)ã€‚è¡Œå…©å€‹æœƒé›™å€å»¶é²ä½†æ”¶ç›Šå¥½å°‘ã€‚
  - å¦‚æœä½ çœŸä¿‚æƒ³å¤šç­–ç•¥èšåˆï¼Œå…¶å¯¦ Multi-Query å·²ç¶“ä¿‚å’åš â€” ä½¢è¡Œ 4 æ¬¡ search ç„¶å¾Œç”¨ RRF èåˆã€‚ä½ æœƒè®Šæˆ RRF-on-RRF-on-RRFï¼Œé‚Šéš›æ•ˆç›Šéæ¸›ã€‚
  - æ›´å¥½å˜…åšæ³•ä¿‚ Modular RAG å˜…æ–¹å¼ï¼šç‚ºæ¯å€‹ query æ€å•±å˜…ç­–ç•¥ï¼Œè€Œå””ä¿‚æ¯å€‹ query éƒ½ç”¨æ™’æ‰€æœ‰ç­–ç•¥ã€‚

- Step 1-2ï¼šåŒ Path A ä¸€æ¨£ â€” èµ·å’— HyDE åŒ Multi-Query å…ˆ
- Step 3ï¼šæ–°å˜¢ â€” èµ·ä¸€å€‹ Classifier å°‡ query è·¯ç”±å»æœ€ä½³ç­–ç•¥
- Bonusï¼šç”¨ Docling metadata (section_title) åš pre-filtering
- ç¸½å…±ï¼šå–º Part 3 code ä¹‹ä¸ŠåŠ ç´„ 80 è¡Œ
-->

---
layout: center
---

# Path B: Key Code â€” Classifier + Router

```python {all|1-9|11-12|14-19|20-21}
def classify_query(query):
    resp = chat_client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[{"role": "user", "content": (
            f"Classify this query as 'factual', 'conceptual', or 'ambiguous'.\n"
            f"Query: {query}\n"
            "Reply with one word only."
        )}],
    )
    return resp.choices[0].message.content.strip().lower()

def modular_rag(conn, query, top_k=5):
    query_type = classify_query(query)
    print(f"ğŸ“‹ Query classified as: {query_type}")

    if "factual" in query_type:
        results = _search_bm25(conn, query, limit=top_k)
    elif "conceptual" in query_type:
        results = hyde_search(conn, query, top_k=top_k)
    else:  # ambiguous
        results = multi_query_search(conn, query, top_k=top_k)
    return results
```

<v-click>
<div class="mt-4 grid grid-cols-3 gap-3 text-xs text-center">
  <div class="p-2 bg-blue-900/30 rounded border border-blue-500">
    <div class="font-bold">"Cap. 228 Â§14"</div>
    <div class="opacity-75">â†’ factual â†’ BM25</div>
  </div>
  <div class="p-2 bg-purple-900/30 rounded border border-purple-500">
    <div class="font-bold">"Explain community policing"</div>
    <div class="opacity-75">â†’ conceptual â†’ HyDE</div>
  </div>
  <div class="p-2 bg-yellow-900/30 rounded border border-yellow-500">
    <div class="font-bold">"Noise issues"</div>
    <div class="opacity-75">â†’ ambiguous â†’ Multi-Query</div>
  </div>
</div>
</v-click>

<!--
**Path B: Classifier + Router Code (3 mins)**

- Line 1-9: classify_query() â€” one LLM call to classify as factual/conceptual/ambiguous
- Line 11-12: modular_rag() â€” the router function
- Line 14-19: Route to the best strategy based on classification
- Line 20-21: Ambiguous queries get Multi-Query (widest net)
- Key: The classifier is a single LLM call â€” fast and cheap
- Students can extend with more categories or metadata-based routing

å»£æ±è©±ï¼š
- Line 1-9ï¼š`classify_query()` â€” ä¸€å€‹ LLM call å»åˆ†é¡åš factual/conceptual/ambiguous
- Line 11-12ï¼š`modular_rag()` â€” è·¯ç”± function
- Line 14-19ï¼šæ ¹æ“šåˆ†é¡è·¯ç”±å»æœ€ä½³ç­–ç•¥
- Line 20-21ï¼šAmbiguous queries å°±ç”¨ Multi-Query (æ’’å¤§ç¶²)
- é—œéµï¼šClassifier åªä¿‚ä¸€å€‹ LLM call â€” åˆå¿«åˆå¹³
- åŒå­¸å¯ä»¥è‡ªå·±åŠ å¤šå•²é¡åˆ¥æˆ–è€… metadata-based routing
-->

---
layout: center
---

# ğŸ”´ Path C: Corrective RAG (CRAG)

<div class="text-sm mb-4">Reranker as Grader + Query Rewriting + Retry Loop</div>

<Transform :scale="1.2" origin="center">

```mermaid
flowchart LR
    Q[ğŸ” Query] --> SEARCH[ğŸ” Hybrid Search]
    SEARCH --> RR[âš–ï¸ _rerank\nAS GRADER]
    RR --> CHECK{Score â‰¥ 0.5?}
    CHECK -->|âœ… Yes| GEN[ğŸ¤– Generate]
    CHECK -->|âŒ No| REWRITE[âœï¸ Rewrite Query]
    REWRITE --> SEARCH

    style Q fill:#3b82f6,color:#fff
    style SEARCH fill:#22c55e,color:#000
    style RR fill:#ef4444,color:#fff
    style CHECK fill:#eab308,color:#000
    style GEN fill:#a855f7,color:#fff
    style REWRITE fill:#ef4444,color:#fff
```

</Transform>

<v-click>
<div class="mt-8 grid grid-cols-3 gap-3 text-xs text-center">
  <div class="p-2 border border-red-500 rounded">Step 1: rewrite_query()</div>
  <div class="p-2 border border-red-500 rounded">Step 2: corrective_rag()</div>
  <div class="p-2 border border-yellow-500 rounded">Step 3: Tune threshold</div>
</div>
</v-click>

<!--
**Path C Overview (2 mins)**

- No HyDE or Multi-Query needed â€” goes straight to retrieval grading
- Step 1: rewrite_query() â€” LLM rewrites failed queries
- Step 2: corrective_rag() â€” the main loop with reranker-as-grader
- Step 3: Tune the threshold (start at 0.5)
- Key insight: Reranker is 10x faster than LLM grading
- Total: ~55 new lines on top of Part 3 code

å»£æ±è©±ï¼š
- å””éœ€è¦ HyDE æˆ– Multi-Query â€” ç›´æ¥å» Retrieval Grading
- Step 1: `rewrite_query()` â€” LLM é‡å¯«å¤±æ•—å˜… queries
- Step 2: `corrective_rag()` â€” ä¸»è¿´åœˆï¼ŒåŒ…å« reranker-as-grader
- Step 3: Tune å€‹ threshold (ç”± 0.5 é–‹å§‹)
- é—œéµï¼šReranker å¿«é LLM grading 10 å€
- ç¸½å…±ï¼šå–º Part 3 code ä¹‹ä¸ŠåŠ ç´„ 55 è¡Œ
-->

---
layout: center
---

# Path C: Key Code â€” Corrective RAG

```python {all|1-6|8-9|11-13|15-16|18-20}
def corrective_rag(conn, query, top_k=5, threshold=0.5, max_retries=2):
    current_query = query
    for attempt in range(max_retries + 1):
        # Retrieve
        candidates = _hybrid_search(conn, current_query, top_k=top_k * 2)
        texts = [c["text"] for c in candidates]

        # Grade using RERANKER (not LLM!) â€” 10x faster
        reranked = _rerank(current_query, texts, top_k=top_k)
        best_score = reranked[0][1] if reranked else 0

        if best_score >= threshold or attempt == max_retries:
            chunks = [{"text": text} for text, score in reranked]
            return _generate_answer(query, chunks)  # original query!

        # Bad docs â†’ rewrite and retry
        resp = chat_client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[{"role": "user", "content":
                f"Rewrite this search query to be more specific:\n{current_query}"}],
        )
        current_query = resp.choices[0].message.content.strip()
```

<!--
**Path C: CRAG Code â€” The Loop (2 mins)**

- Line 1-6: Main loop â€” retrieve with hybrid search
- Line 8-9: THE KEY INSIGHT â€” use _rerank() as a grader, not an LLM
- Line 11-13: If score is good enough OR out of retries â†’ generate answer
- Line 15-16: Note: generate with ORIGINAL query, not rewritten one
- Line 18-20: Rewrite the query using LLM and retry

å»£æ±è©±ï¼š
- Line 1-6ï¼šä¸»è¿´åœˆ â€” ç”¨ hybrid search æµå˜¢
- Line 8-9ï¼š**é—œéµæ´è¦‹** â€” ç”¨ `_rerank()` åš graderï¼Œå””ä¿‚ LLM
- Line 11-13ï¼šå¦‚æœåˆ†æ•¸å¤ é«˜ OR ç„¡å¾—å† retry â†’ ç”Ÿæˆç­”æ¡ˆ
- Line 15-16ï¼šç•™æ„ï¼šç”¨ **åŸè£** query ç”Ÿæˆï¼Œå””ä¿‚é‡å¯«å—°å€‹
- Line 18-20ï¼šç”¨ LLM é‡å¯« query å† retry
-->

---
layout: center
---

# Path C: Key Insights â€” Why Reranker as Grader?

<div class="grid grid-cols-2 gap-6 mt-6">
  <div class="p-4 bg-red-900/30 rounded-lg border border-red-500">
    <div class="font-bold text-red-400 text-lg mb-2">âš–ï¸ Reranker as Grader</div>
    <div class="text-sm opacity-85">Score &lt; 0.5 â†’ docs are irrelevant â†’ rewrite query</div>
    <div class="text-sm opacity-85">Score â‰¥ 0.5 â†’ docs are good â†’ generate answer</div>
    <div class="text-xs opacity-60 mt-2">Trained specifically for relevance scoring â€” not a hack!</div>
  </div>
  <div class="p-4 bg-yellow-900/30 rounded-lg border border-yellow-500">
    <div class="font-bold text-yellow-400 text-lg mb-2">â±ï¸ Latency Budget</div>
    <div class="text-sm opacity-85">Reranker grades 5 docs: ~200ms</div>
    <div class="text-sm opacity-85">LLM grades 5 docs: ~2-3s</div>
    <div class="text-xs opacity-60 mt-2">In a retry loop, this 10Ã— speed difference matters</div>
  </div>
</div>

<v-click>
<div class="mt-6 p-4 bg-cyan-900/20 rounded-lg border border-cyan-500 text-center">
  <div class="text-sm">ğŸ’¡ <strong class="text-cyan-400">Worst case</strong>: 2 retries Ã— (search + rerank + rewrite) â‰ˆ <strong>8 seconds</strong></div>
  <div class="text-xs opacity-75 mt-1">Still faster than one LLM-as-grader call per retry</div>
</div>
</v-click>

<v-click>
<div class="mt-4 p-3 bg-purple-900/20 rounded-lg border border-purple-500 text-center text-sm">
  ğŸ”‘ <code>return _generate_answer(<span class="text-green-400">query</span>, chunks)</code> â€” always use the <strong class="text-green-400">original</strong> query for generation, not the rewritten one
</div>
</v-click>

<!--
**Path C: Key Insights (1 min)**

- Why reranker and not LLM as grader? Speed. Reranker is trained for relevance scoring â€” it's not a hack, it's the right tool.
- Reranker: ~200ms for 5 docs. LLM: ~2-3s for 5 docs. In a retry loop with 2 retries, that's 0.6s vs 6s just for grading.
- Worst case: 2 retries = 3 rounds of (search + rerank + rewrite) â‰ˆ 8s total. Still acceptable for high-stakes queries.
- IMPORTANT DETAIL: Always generate with the ORIGINAL query, not the rewritten one. The rewritten query is optimized for search, not for answering.

å»£æ±è©±ï¼š
- é»è§£ç”¨ Reranker å””ç”¨ LLM åš graderï¼Ÿé€Ÿåº¦ã€‚Reranker å°ˆé–€è¨“ç·´åšŸè¨ˆç›¸é—œæ€§ â€” å””ä¿‚ hackï¼Œä¿‚å•±å˜…å·¥å…·ã€‚
- Rerankerï¼š5 ä»½æ–‡ä»¶ ~200msã€‚LLMï¼š5 ä»½æ–‡ä»¶ ~2-3sã€‚å–º retry loop å…¥é¢æœ‰ 2 æ¬¡ retryï¼Œå³ä¿‚ 0.6s vs 6s æ·¨ä¿‚ gradingã€‚
- æœ€å£æƒ…æ³ï¼š2 æ¬¡ retry = 3 è¼ª (search + rerank + rewrite) â‰ˆ 8s ç¸½å…±ã€‚å°é«˜é¢¨éšª query åšŸè¬›ä»²å¯ä»¥æ¥å—ã€‚
- é‡è¦ç´°ç¯€ï¼šæ°¸é ç”¨ **åŸè£** query ç”Ÿæˆç­”æ¡ˆï¼Œå””ä¿‚é‡å¯«å—°å€‹ã€‚é‡å¯«å˜… query ä¿‚ç‚º search å„ªåŒ–ï¼Œå””ä¿‚ç‚ºç­”å•é¡Œå„ªåŒ–ã€‚
-->

---
layout: center
---

# ğŸŸ£ Path D: Self-RAG

<div class="text-sm mb-4">Generate â†’ Reflect â†’ Improve Loop</div>

<Transform :scale="1.0" origin="center">

```mermaid
flowchart LR
    Q[ğŸ” Query] --> SEARCH[ğŸ” Hybrid Search]
    SEARCH --> GEN[ğŸ¤– Generate Draft]
    GEN --> REFLECT[ğŸª Reflect]
    REFLECT --> CHECK{Sufficient?}
    CHECK -->|âœ… Yes| OUT[ğŸ“¤ Output]
    CHECK -->|âŒ No| MORE[ğŸ” Retrieve More]
    MORE --> GEN

    style Q fill:#3b82f6,color:#fff
    style SEARCH fill:#22c55e,color:#000
    style GEN fill:#a855f7,color:#fff
    style REFLECT fill:#eab308,color:#000
    style CHECK fill:#eab308,color:#000
    style OUT fill:#22c55e,color:#000
    style MORE fill:#ef4444,color:#fff
```

</Transform>

<v-click>
<div class="mt-4 grid grid-cols-3 gap-3 text-xs text-center">
  <div class="p-2 border border-purple-500 rounded">Step 1: reflect_on_answer()</div>
  <div class="p-2 border border-purple-500 rounded">Step 2: self_rag()</div>
  <div class="p-2 border border-yellow-500 rounded">Step 3: Tune iterations</div>
</div>
</v-click>

<!--
**Path D Overview (2 mins)**

- No HyDE or Multi-Query needed â€” goes straight to answer quality
- Step 1: reflect_on_answer() â€” LLM critiques its own answer
- Step 2: self_rag() â€” the main generate â†’ reflect â†’ improve loop
- Step 3: Tune max_iterations (start at 2)
- Key: The 8B model on GPU handles reflection well â€” fast enough to iterate
- Total: ~50 new lines on top of Part 3 code

å»£æ±è©±ï¼š
- å””éœ€è¦ HyDE æˆ– Multi-Query â€” ç›´æ¥å»æ Answer Quality
- Step 1: `reflect_on_answer()` â€” LLM æ‰¹åˆ¤è‡ªå·±å€‹ç­”æ¡ˆ
- Step 2: `self_rag()` â€” ä¸»è¿´åœˆï¼šgenerate â†’ reflect â†’ improve
- Step 3: Tune max_iterations (ç”± 2 é–‹å§‹)
- é—œéµï¼šGPU ä¸Šå˜… 8B model åš reflection åšå¾—å¹¾å¥½ â€” å¤ å¿«å¯ä»¥ iterate
- ç¸½å…±ï¼šå–º Part 3 code ä¹‹ä¸ŠåŠ ç´„ 50 è¡Œ
-->

---
layout: center
---

# Path D: Key Code â€” The Reflection Function

```python {all|1-3|4-7|9}
def reflect_on_answer(query, answer, context):
    resp = chat_client.chat.completions.create(
        model=CHAT_MODEL,
        messages=[{"role": "user", "content": (
            f"Evaluate this answer.\nQuestion: {query}\n"
            f"Context: {context[:500]}\nAnswer: {answer}\n\n"
            "Reply 'SUFFICIENT' or 'NEEDS_IMPROVEMENT: <what is missing>'"
        )}],
    )
    return resp.choices[0].message.content.strip()
```

<v-click>
<div class="mt-6 grid grid-cols-2 gap-4 text-sm">
  <div class="p-3 bg-purple-900/30 rounded-lg border border-purple-500">
    <div class="font-bold text-purple-400 mb-1">ğŸª LLM-as-a-Judge</div>
    <div class="text-xs opacity-85">Same model that wrote the answer now <strong>critiques</strong> it</div>
    <div class="text-xs opacity-75 mt-1">Returns "SUFFICIENT" or "NEEDS_IMPROVEMENT: ..."</div>
  </div>
  <div class="p-3 bg-yellow-900/30 rounded-lg border border-yellow-500">
    <div class="font-bold text-yellow-400 mb-1">ğŸ“ Context Truncation</div>
    <div class="text-xs opacity-85"><code>context[:500]</code> â€” keep reflection prompt short</div>
    <div class="text-xs opacity-75 mt-1">Reflection doesn't need full context, just enough to check</div>
  </div>
</div>
</v-click>

<!--
**Path D: Reflection Function (2 mins)**

- Line 1-3: Call the same LLM that generated the answer â€” now as a JUDGE
- Line 4-7: The prompt asks: "Is this answer sufficient given the context?" Binary output: SUFFICIENT or NEEDS_IMPROVEMENT
- Line 9: Return the raw reflection text
- This is the LLM-as-a-Judge pattern â€” but the judge is the same model that wrote the answer
- context[:500] â€” we truncate context for the reflection prompt. The reflection doesn't need the full context, just enough to verify the answer.

å»£æ±è©±ï¼š
- Line 1-3ï¼šCall åŒä¸€å€‹ LLM â€” è€Œå®¶åš JUDGE
- Line 4-7ï¼šPrompt å•ï¼šã€Œå‘¢å€‹ç­”æ¡ˆå¤ å””å¤ å¥½ï¼Ÿã€äºŒå…ƒè¼¸å‡ºï¼šSUFFICIENT æˆ– NEEDS_IMPROVEMENT
- Line 9ï¼šReturn åŸå§‹ reflection æ–‡å­—
- å‘¢å€‹ä¿‚ LLM-as-a-Judge pattern â€” ä½†å€‹ judge åŒå¯«ç­”æ¡ˆå—°å€‹ä¿‚åŒä¸€å€‹ model
- `context[:500]` â€” æˆªçŸ­ context ä¿¾ reflection promptã€‚Reflection å””éœ€è¦å®Œæ•´ contextï¼Œå¤ é©—è­‰å°±å¾—ã€‚
-->

---
layout: center
---

# Path D: Key Code â€” The Self-RAG Loop

```python {all|1-3|5-10|12-15|17-18}
def self_rag(conn, query, top_k=5, max_iterations=2):
    chunks = _hybrid_search(conn, query, top_k=top_k)
    for iteration in range(max_iterations):
        context = "\n\n".join(c["text"] for c in chunks)

        # Generate
        resp = chat_client.chat.completions.create(
            model=CHAT_MODEL,
            messages=[{"role": "user",
                "content": f"Context:\n{context}\n\nQuestion: {query}\n\nAnswer:"}],
        )
        answer = resp.choices[0].message.content

        # Reflect
        reflection = reflect_on_answer(query, answer, context)
        if "SUFFICIENT" in reflection.upper():
            return answer

        # Retrieve more context for next iteration
        chunks = _hybrid_search(conn, query, top_k=top_k + 3)
    return answer
```

<v-click>
<div class="mt-3 p-3 border border-purple-500 rounded-lg bg-purple-900/20 text-center text-xs">
  â±ï¸ Each iteration â‰ˆ 4s on GPU Â· Worst case (2 iterations) â‰ˆ 8s Â· LLM is both <span class="text-purple-400 font-bold">writer</span> and <span class="text-yellow-400 font-bold">editor</span>
</div>
</v-click>

<!--
**Path D: Self-RAG Loop (2 mins)**

- Line 1-3: Start with hybrid search, then loop up to max_iterations
- Line 5-10: Generate a draft answer from context
- Line 12-15: Reflect â€” if SUFFICIENT, return immediately (early exit!)
- Line 17-18: If not sufficient, retrieve MORE context (top_k + 3) and try again
- Key: The 8B model handles reflection well â€” it can genuinely critique its own output
- Worst case: 2 iterations Ã— (generate + reflect) â‰ˆ 8s. Each iteration adds more context.

å»£æ±è©±ï¼š
- Line 1-3ï¼šç”± hybrid search é–‹å§‹ï¼Œç„¶å¾Œ loop æœ€å¤š max_iterations æ¬¡
- Line 5-10ï¼šæ ¹æ“š context ç”Ÿæˆåˆç¨¿
- Line 12-15ï¼šReflect â€” å¦‚æœ SUFFICIENTï¼Œå³åˆ» returnï¼ˆææ—©é€€å‡ºï¼ï¼‰
- Line 17-18ï¼šå¦‚æœå””è¶³å¤ ï¼ŒRetrieve **æ›´å¤š** context (top_k + 3) å†è©¦ä¸€æ¬¡
- é—œéµï¼š8B model è™•ç† reflection å¥½å¥½ â€” ä½¢çœŸä¿‚è­˜æ‰¹åˆ¤è‡ªå·±å˜… output
- æœ€å£æƒ…æ³ï¼š2 æ¬¡ iteration Ã— (generate + reflect) â‰ˆ 8sã€‚æ¯æ¬¡ iteration åŠ å¤šå•² contextã€‚
-->

---
layout: center
---

# âš–ï¸ Reranking Integration Map

<div class="text-sm mb-4">How <code>_rerank()</code> fits into each path</div>

<Transform :scale="1.2" origin="center">

```mermaid
flowchart TB
    RR[âš–ï¸ qwen3-vl-reranker-2b\nRemote GPU]
    RR ---|After HyDE/Multi-Query\ncorrects drift| A[ğŸŸ¢ Path A\nâ­â­â­â­â­ Optional]
    RR ---|Post-retrieval\nin each route| B[ğŸŸ¡ Path B\nâ­â­â­ Optional]
    RR ---|REPLACES LLM grader\nscores 0-1| C[ğŸ”´ Path C\nâ­â­â­â­â­ REQUIRED]
    RR ---|Better initial context\nfewer iterations| D[ğŸŸ£ Path D\nâ­â­â­ Optional]

    style RR fill:#3b82f6,color:#fff
    style A fill:#22c55e,color:#000
    style B fill:#eab308,color:#000
    style C fill:#ef4444,color:#fff
    style D fill:#a855f7,color:#fff
```

</Transform>

<v-click>
<div class="mt-6 grid grid-cols-2 gap-4 text-xs">
  <div class="p-3 border border-green-500 rounded-lg bg-green-900/20">
    <div class="font-bold text-green-400 mb-1">ğŸŸ¢ Optional (A, B, D)</div>
    <div>Reranking <span class="text-green-400">enhances</span> search quality â€” the core algorithm works without it</div>
  </div>
  <div class="p-3 border border-red-500 rounded-lg bg-red-900/20">
    <div class="font-bold text-red-400 mb-1">ğŸ”´ Required (C)</div>
    <div>Reranker <span class="text-red-400">IS</span> the grading mechanism â€” its 0-1 scores enable threshold decisions. Without it, you'd need an LLM call per document (10Ã— slower)</div>
  </div>
</div>
</v-click>

<!--
**Reranking Integration Map (2 mins)**

- Path A: Reranking corrects HyDE drift and filters Multi-Query noise â€” nice quality boost but works without it
- Path B: Already routing to best strategy, reranking adds marginal improvement
- Path C: Reranker IS the grader â€” REQUIRED. The reranker's 0-1 scores with clear separation (>0.5 relevant, <0.3 irrelevant) enable threshold-based decisions. Without it, you'd need an LLM call per document â€” 10x slower and less reliable. The reranker doesn't enhance search â€” it IS the algorithm.
- Path D: Better initial context = fewer reflection iterations, but the loop compensates
- Key: Reranking is optional for most paths, but REQUIRED for Path C (CRAG)

å»£æ±è©±ï¼š
- Path Aï¼šReranking ä¿®æ­£ HyDE åå·®åŒéæ¿¾ Multi-Query é›œè¨Š â€” éŒ¦ä¸Šæ·»èŠ±ï¼Œä½†ç„¡ä½¢éƒ½é‹ä½œåˆ°
- Path Bï¼šå·²ç¶“è·¯ç”±å»æœ€ä½³ç­–ç•¥ï¼ŒReranking åªæœ‰é‚Šéš›æå‡
- Path Cï¼šReranker **å°±ä¿‚** å€‹ Grader â€” **å¿…é ˆ**ã€‚Reranker å˜… 0-1 åˆ†æ•¸åˆ†ç•Œå¥½æ¸… (>0.5 relevant, <0.3 irrelevant)ï¼Œå¯ä»¥ç”¨ threshold åšæ±ºå®šã€‚ç„¡å’—ä½¢ï¼Œä½ è¦é€ä»½æ–‡ä»¶ call LLM â€” æ…¢ 10 å€å…¼ç„¡å’æº–ã€‚
- Path Dï¼šåˆå§‹ context æº–å•² = å°‘å•² Reflection iterations
- é—œéµï¼šReranking å°å¤§éƒ¨åˆ†è·¯ä¿‚ Optionalï¼Œä½†å° Path C (CRAG) ä¿‚ Required
-->

---
layout: center
---

# ğŸš€ Going Further: Combining Paths

<div class="text-sm opacity-75 mb-4">Advanced Discussion â€” not for today's hands-on</div>

<div class="text-xs mb-4">Each path guards a <span class="text-yellow-400 font-bold">different failure point</span> in the pipeline:</div>

<Transform :scale="1.3" origin="center">

```mermaid
flowchart LR
    Q[â“ Query] --> QF["ğŸ”§ Query Fix\n(Path A / B)"]
    QF --> S[ğŸ” Search]
    S --> RF["âš–ï¸ Retrieval Fix\n(Path C)"]
    RF --> G[ğŸ¤– Generate]
    G --> AF["ğŸª Answer Fix\n(Path D)"]
    AF --> O[âœ… Output]

    style Q fill:#3b82f6,color:#fff
    style QF fill:#22c55e,color:#000
    style S fill:#3b82f6,color:#fff
    style RF fill:#ef4444,color:#fff
    style G fill:#a855f7,color:#fff
    style AF fill:#a855f7,color:#fff
    style O fill:#22c55e,color:#000
```

</Transform>

<!--
**Going Further: Combining Paths (2 mins)**

- Key insight: Each path guards a different pipeline stage. A single path = one guard. Combining = defense-in-depth.
- Show the pipeline diagram: Query â†’ [Query Fix: A/B] â†’ Search â†’ [Retrieval Fix: C] â†’ Generate â†’ [Answer Fix: D] â†’ Output
- These aren't competing techniques â€” they're layers. Production RAG systems combine them.
- This is advanced discussion only â€” students should master one path first before thinking about combinations.

å»£æ±è©±ï¼š
- é—œéµï¼šæ¯æ¢è·¯å®ˆä½ Pipeline å””åŒéšæ®µã€‚å–®ä¸€æ¢è·¯ = ä¸€å€‹å®ˆè¡›ã€‚çµåˆ = ç¸±æ·±é˜²ç¦¦ (Defense-in-depth)ã€‚
- ç‡åœ–ï¼šQuery â†’ [Query Fix: A/B] â†’ Search â†’ [Retrieval Fix: C] â†’ Generate â†’ [Answer Fix: D] â†’ Output
- ä½¢å“‹å””ä¿‚äº’ç›¸æ’æ–¥ â€” ä¿‚ä¸€å±¤å±¤åŠ ä¸Šå»ã€‚Production RAG systems æœƒçµåˆä½¢å“‹ã€‚
- å‘¢å€‹åªä¿‚é€²éšè¨è«– â€” åŒå­¸æ‡‰è©²å…ˆæŒæ¡ä¸€æ¢è·¯ï¼Œå…ˆå¥½è«—çµåˆã€‚
-->

---
layout: center
---

# ğŸš€ Three Meaningful Combinations

<div class="text-xs opacity-75 mb-6">Layer your building blocks for production-grade RAG</div>

<div class="grid grid-cols-3 gap-4 text-xs">
  <v-click>
  <div class="p-4 border-2 border-yellow-500 rounded-xl bg-yellow-900/10">
    <div class="text-2xl mb-2">ğŸ”€</div>
    <div class="font-bold text-yellow-400 mb-1">B + C: Adaptive CRAG</div>
    <div class="text-[10px] opacity-75 mb-2">Router + Retrieval Gate</div>
    <div class="mb-2">Router picks best strategy â†’ CRAG grades results â†’ <span class="text-yellow-400">retry with different strategy</span> if bad</div>
    <div class="p-2 bg-yellow-900/30 rounded text-[10px]">
      ğŸ“‹ Multi-dept portal: BM25 fails on legal jargon â†’ CRAG retries with HyDE automatically
    </div>
  </div>
  </v-click>
  <v-click>
  <div class="p-4 border-2 border-red-500 rounded-xl bg-red-900/10">
    <div class="text-2xl mb-2">ğŸ›¡ï¸</div>
    <div class="font-bold text-red-400 mb-1">C + D: Verified RAG</div>
    <div class="text-[10px] opacity-75 mb-2">Retrieval Gate + Answer Gate</div>
    <div class="mb-2">CRAG catches <span class="text-red-400">wrong docs</span> â†’ Self-RAG catches <span class="text-red-400">wrong interpretation</span></div>
    <div class="p-2 bg-red-900/30 rounded text-[10px]">
      ğŸš¨ Emergency procedures: wrong doc = wrong procedure. Wrong interpretation = also danger.
    </div>
  </div>
  </v-click>
  <v-click>
  <div class="p-4 border-2 border-purple-500 rounded-xl bg-purple-900/10">
    <div class="text-2xl mb-2">ğŸ­</div>
    <div class="font-bold text-purple-400 mb-1">B + C + D: Production RAG</div>
    <div class="text-[10px] opacity-75 mb-2">Full Pipeline</div>
    <div class="mb-2">Smart routing â†’ retrieval quality gate â†’ answer quality gate. <span class="text-purple-400">Defense-in-depth.</span></div>
    <div class="p-2 bg-purple-900/30 rounded text-[10px]">
      ğŸ›ï¸ Citizen-facing gov AI: diverse users + high stakes = guard every stage
    </div>
  </div>
  </v-click>
</div>

<v-click>
<div class="mt-4 p-3 border border-blue-500 rounded-lg bg-blue-900/20 text-center text-xs">
  ğŸ’¡ These aren't competing techniques â€” they're <span class="text-blue-400 font-bold">layers</span>. Master one path first, then combine.
</div>
</v-click>

<!--
**Three Meaningful Combinations (3 mins)**

- B + C "Adaptive CRAG": The router reduces failures, but even the right strategy can miss. CRAG catches what the router can't. The retry becomes smarter â€” switch strategies instead of just rewriting queries.
- C + D "Verified RAG": Subtle failure mode â€” CRAG catches wrong documents, but Self-RAG checks "is the answer supported by context?" If context is wrong but answer faithfully reflects wrong context, Self-RAG alone would say SUFFICIENT. You need BOTH gates.
- B + C + D "Production RAG": This is what real production RAG systems look like. We teach them separately so students understand each mechanism. In reality, you layer them.
- Key message: The question isn't "should you combine?" â€” it's "which failure modes matter most for YOUR use case?"
- Combinations that DON'T work: A+B is redundant (B already uses HyDE/Multi-Query as routing targets). A+D skips the middle (retrieval unguarded).

å»£æ±è©±ï¼š
- B + C "Adaptive CRAG"ï¼šRouter æ¸›å°‘å¤±æ•—ï¼Œä½†å°±ç®—ç­–ç•¥å•±éƒ½å¯èƒ½æœƒ missã€‚CRAG å®ˆå°¾é–€ã€‚Retry å¯ä»¥è®Šè°æ˜å•² â€” è½‰ç­–ç•¥è€Œå””ä¿‚åªä¿‚é‡å¯« queryã€‚
- C + D "Verified RAG"ï¼šå¾®å¦™å˜…å¤±æ•— â€” CRAG æ‰éŒ¯æ–‡ä»¶ï¼Œä½† Self-RAG check "ç­”æ¡ˆä¿‚å’ªç”± context æ”¯æŒï¼Ÿ" å¦‚æœ context éŒ¯ä½†ç­”æ¡ˆå¿ å¯¦åæ˜ éŒ¯ contextï¼Œå–®ç”¨ Self-RAG æœƒè©± SUFFICIENTã€‚ä½ éœ€è¦ **å…©å€‹** é–˜é–€ã€‚
- B + C + D "Production RAG"ï¼šçœŸæ­£ Production RAG ä¿‚å’æ¨£ã€‚æˆ‘å“‹åˆ†é–‹æ•™ä¿‚ç­‰åŒå­¸æ˜ç™½æ¯å€‹æ©Ÿåˆ¶ã€‚ç¾å¯¦ä¸­ä¿‚æœƒç–ŠåŸ‹ä¸€é½Šã€‚
- é—œéµï¼šå•é¡Œå””ä¿‚ã€Œæ‡‰å””æ‡‰è©²çµåˆã€ï¼Œè€Œä¿‚ã€Œé‚Šç¨®å¤±æ•—æ¨¡å¼å° **ä½ ** å˜… Use case æœ€é‡è¦ï¼Ÿã€
-->

---
layout: center
---

# ğŸ—ï¸ What You've Built in 3 Days

<div class="grid grid-cols-3 gap-6 text-center">
  <v-click>
  <div class="p-5 border-2 border-blue-500 rounded-xl">
    <div class="text-4xl mb-3">ğŸ“„</div>
    <div class="text-lg font-bold text-blue-400">Ingestion</div>
    <div class="text-xs mt-3 space-y-1">
      <div>Docling PDF/DOCX parsing</div>
      <div>VLM picture descriptions</div>
      <div>Table extraction</div>
      <div>Hierarchical chunking</div>
    </div>
  </div>
  </v-click>
  <v-click>
  <div class="p-5 border-2 border-green-500 rounded-xl">
    <div class="text-4xl mb-3">ğŸ”</div>
    <div class="text-lg font-bold text-green-400">Retrieval</div>
    <div class="text-xs mt-3 space-y-1">
      <div>BM25 keyword search</div>
      <div>Vector similarity search</div>
      <div>Hybrid search + RRF</div>
      <div>Reranking</div>
    </div>
  </div>
  </v-click>
  <v-click>
  <div class="p-5 border-2 border-purple-500 rounded-xl">
    <div class="text-4xl mb-3">ğŸ§ </div>
    <div class="text-lg font-bold text-purple-400">Intelligence</div>
    <div class="text-xs mt-3 space-y-1">
      <div>HyDE / Multi-Query</div>
      <div>Modular routing</div>
      <div>Corrective RAG</div>
      <div>Self-RAG reflection</div>
    </div>
  </div>
  </v-click>
</div>

<v-click>
<div class="mt-6 text-center text-sm opacity-75">
  From raw PDF â†’ intelligent, self-correcting answers â€” all built by you ğŸ‰
</div>
</v-click>

<!--
**Workshop Conclusion (2 mins)**

- Three pillars of a production RAG system:
  1. Ingestion: Docling handles complex documents (tables, images, hierarchies)
  2. Retrieval: Multiple search strategies, hybrid fusion, reranking
  3. Intelligence: Advanced techniques that fix specific failure modes
- Everything built on top of each other â€” Day 1 â†’ Day 2 â†’ Day 3
- All code is yours to keep and adapt for your own use cases

å»£æ±è©±ï¼š
- Production RAG ä¸‰å¤§æ”¯æŸ±ï¼š
  1. Ingestionï¼šDocling è™•ç†è¤‡é›œæ–‡ä»¶ (è¡¨æ ¼ã€åœ–ç‰‡ã€çµæ§‹)
  2. Retrievalï¼šå¤šç¨®æœå°‹ç­–ç•¥ã€Hybrid fusionã€Reranking
  3. Intelligenceï¼šé‡å°ç‰¹å®šå¤±æ•—æ¨¡å¼å˜…é€²éšæŠ€è¡“
- æ‰€æœ‰å˜¢éƒ½ä¿‚ä¸€å±¤å±¤ç–Šä¸Šå» â€” Day 1 â†’ Day 2 â†’ Day 3
- æ‰€æœ‰ code éƒ½ä¿‚ä½ å˜…ï¼Œéš¨ä¾¿æ‹å»æ”¹åšè‡ªå·±å˜… use case
-->

---
layout: center
---

# ğŸ¯ Key Takeaway

<div class="text-3xl font-bold mt-8 mb-8 text-center leading-relaxed">
  There's no <span class="text-red-400">"best"</span> RAG.<br>
  There's the RAG that <span class="text-green-400">fits your problem</span>.
</div>

<v-click>
<div class="text-lg text-center opacity-75">
  You already had the pieces â€”<br>
  today you learned how to <span class="text-yellow-400 font-bold">arrange them</span>.
</div>
</v-click>

<!--
**Key Takeaway (1 min)**

- No single technique is universally best
- Match the technique to your failure mode:
  - Bad queries â†’ Multi-Query / HyDE
  - Wrong strategy â†’ Modular RAG
  - Bad retrieval â†’ CRAG
  - Bad answers â†’ Self-RAG
- The building blocks are the same â€” it's the arrangement that matters
- You now have a toolkit, not just a tool

å»£æ±è©±ï¼š
- ç„¡æ‰€è¬‚ **ã€Œæœ€å¥½ã€** å˜… RAG æŠ€è¡“
- è¦æ€é…åˆä½  **å¤±æ•—æ¨¡å¼** å˜…æŠ€è¡“ï¼š
  - çˆ› Queries â†’ Multi-Query / HyDE
  - éŒ¯ç­–ç•¥ â†’ Modular RAG
  - çˆ› Retrieval â†’ CRAG
  - çˆ› Answers â†’ Self-RAG
- ç©æœ¨ä¿‚å—°å¹¾èˆŠ â€” é‡é»ä¿‚é»æ¨£ **æ’åˆ—** ä½¢å“‹
- ä½ ä¾å®¶æœ‰ä¸€å¥—å·¥å…·ç®±ï¼Œå””æ­¢ä¿‚å–®ä¸€ä»¶å·¥å…·
-->

---
layout: center
---

<div class="text-5xl mb-6">ğŸ™</div>

# Thank You

<div class="text-xl opacity-75 mt-4">Questions?</div>

<div class="mt-8 text-sm opacity-50">
  Day 1: Search Foundations Â· Day 2: Hybrid + Reranking Â· Day 3: Advanced RAG
</div>